{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки, которые необходимы для работы \n",
    "- numpy и pandas - вектора и матрицы\n",
    "- nltk - основная библиотека для работы с nlp\n",
    "- sklearn - библиотека для машинного обучения\n",
    "- pymorphy2 - морфологический анализатор (приведение слов к нормальной форме)\n",
    "- vaderSentiment - пакет для анализа тональности текста\n",
    "- re - работа с регулярными выражениями\n",
    "- nlpia - получение датасетов\n",
    "- collections - специализированные типы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка текста делится на следующие этапы:\n",
    "1. Токенизация (разделение на слова и предложения)\n",
    "2. Приведение к нижнему регистру\n",
    "3. Удаление стоп-слов, знаков препинания, числовых значений\n",
    "4. Лемматизация (Приведение к нормальной форме слова)\n",
    "5. Стемминг (Приведение к основе слова)\n",
    "6. Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительная обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмём исходный текст для анализа\n",
    "corpus = 'When we were in Paris we visited a lot of museums. We first went to the Louvre, the largest art museum in the world. I have always been interested in art so I spent many hours there. The museum is enourmous, so a week there would not be enough.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1. Токенизация "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизация с помощью word_tokenize и sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FerrariBoy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When we were in Paris we visited a lot of museums.',\n",
       " 'We first went to the Louvre, the largest art museum in the world.',\n",
       " 'I have always been interested in art so I spent many hours there.',\n",
       " 'The museum is enourmous, so a week there would not be enough.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# импортируем метод sent_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Разделим  текст на предложения\n",
    "# скачиваем модель, которая будет делить на предложения\n",
    "nltk.download('punkt')\n",
    "print('')\n",
    "\n",
    "# и применяем метод к нашему тексту\n",
    "sentences = sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'we', 'were', 'in', 'Paris', 'we', 'visited', 'a', 'lot', 'of', 'museums', '.']\n"
     ]
    }
   ],
   "source": [
    "# разобьём на слова первое предложение\n",
    "print(word_tokenize(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'we', 'were', 'in', 'Paris', 'we', 'visited', 'a', 'lot', 'of', 'museums', '.', 'We', 'first', 'went', 'to', 'the', 'Louvre', ',', 'the', 'largest', 'art', 'museum', 'in', 'the', 'world', '.', 'I', 'have', 'always', 'been', 'interested', 'in', 'art', 'so', 'I', 'spent', 'many', 'hours', 'there', '.', 'The', 'museum', 'is', 'enourmous', ',', 'so', 'a', 'week', 'there', 'would', 'not', 'be', 'enough', '.']\n"
     ]
    }
   ],
   "source": [
    "# теперь проделаем это со всеми предложениями\n",
    "\n",
    "# для этого создадим пустой список\n",
    "tokens = []\n",
    "# в цикле for пройдемся по каждому предложению\n",
    "for sentence in sentences:\n",
    "    # создадим списки из токенов\n",
    "    t = word_tokenize(sentence)\n",
    "    # и присоединим списки друг к другу\n",
    "    tokens.extend(t)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизация с помощью RegexpTokenizer или TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " 'we',\n",
       " 'were',\n",
       " 'in',\n",
       " 'Paris',\n",
       " 'we',\n",
       " 'visited',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'museums',\n",
       " '.',\n",
       " 'We',\n",
       " 'first',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Louvre',\n",
       " ',',\n",
       " 'the',\n",
       " 'largest',\n",
       " 'art',\n",
       " 'museum',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'always',\n",
       " 'been',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'art',\n",
       " 'so',\n",
       " 'I',\n",
       " 'spent',\n",
       " 'many',\n",
       " 'hours',\n",
       " 'there',\n",
       " '.',\n",
       " 'The',\n",
       " 'museum',\n",
       " 'is',\n",
       " 'enourmous',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'week',\n",
       " 'there',\n",
       " 'would',\n",
       " 'not',\n",
       " 'be',\n",
       " 'enough',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
    "#tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенезация неформального текста из социальных сетей, таких как  Twitter  Facebook\n",
    "\n",
    "Библиотека NLTK включает в себя токенизатор casual_tokenize для работы с короткими, неформальными, сдобренными смайликами текстами из социальных сетей, где грамматика и правописание сильно варьируются.\n",
    "Функцией casual_tokenize можно выделять имена пользователей и сокращать количество повторяющихся символов в токене:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@TJMonticello', 'Best', 'day', 'everrrrrrr', 'at', 'Monticello', '.', 'Awesommmmmmeeeeeeee', 'day', ':*)']\n",
      "['RT', 'Best', 'day', 'everrr', 'at', 'Monticello', '.', 'Awesommmeee', 'day', ':*)']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize\n",
    "message = \"RT @TJMonticello Best day everrrrrrr at Monticello. Awesommmmmmeeeeeeee day :*)\"\n",
    "print(casual_tokenize(message))\n",
    "print(casual_tokenize(message, reduce_len=True, strip_handles=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. Перевод текста в нижний регистр + Шаг 3. Удаление стоп-слов и пунктуации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Стоп-слова — это распространенные слова на любом языке, которые встречаются очень часто, но несут в себе гораздо меньше содержательной информации о смысле фразы. Вот примеры некоторых распространенных стоп-слов:\n",
    "\n",
    "1.    a, an;\n",
    "2.   the, this;\n",
    "3.   the, this;\n",
    "4.   of, on.\n",
    "5.   and, or;\n",
    "\n",
    "С одной стороны, удаление стоп-слов может привести к потере смысловой составляющей текста, но с другой, увеличению словаря и используемых мощностей. Поэтому процесс фильтра стоп-слов \n",
    "зависит от конкретной ситуации.\n",
    "\n",
    "В зависимости от используемой библиотеки готовый набор стоп-слов может отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['paris', 'visited', 'lot', 'museums', 'first', 'went', 'louvre', 'largest', 'art', 'museum', 'world', 'always', 'interested', 'art', 'spent', 'many', 'hours', 'museum', 'enourmous', 'week', 'would', 'enough']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FerrariBoy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# импортируем модуль стоп-слов\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# скачаем словарь стоп-слов\n",
    "nltk.download('stopwords')\n",
    "print('')\n",
    "\n",
    "# мы используем set, чтобы оставить только уникальные значения\n",
    "unique_stops = set(stopwords.words('english'))\n",
    "# создаём пустой список без стоп-слов\n",
    "no_stops = []\n",
    "# проходимся по всем токенам\n",
    "for token in tokens:\n",
    "    # переводим все слова в нижний регистр\n",
    "    token = token.lower()\n",
    "    # если токен не в списке стоп-слов и не является знаком пунктуации\n",
    "    if token not in unique_stops and token.isalpha():\n",
    "        # добавляем его в список\n",
    "        no_stops.append(token)\n",
    "\n",
    "print(no_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. Лемматизация (Приведение к нормальной форме)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры пакетов для лемматизации:\n",
    "\n",
    "- Wordnet Lemmatizer\n",
    "\n",
    "- Spacy Lemmatizer\n",
    "\n",
    "- TextBlob\n",
    "\n",
    "- CLiPS Pattern\n",
    "\n",
    "- Stanford CoreNLP\n",
    "\n",
    "- Gensim Lemmatizer\n",
    "\n",
    "- TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FerrariBoy\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['paris', 'visited', 'lot', 'museum', 'first', 'went', 'louvre', 'largest', 'art', 'museum', 'world', 'always', 'interested', 'art', 'spent', 'many', 'hour', 'museum', 'enourmous', 'week', 'would', 'enough']\n"
     ]
    }
   ],
   "source": [
    "# импортируем класс для лемматизации\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# импортируем словарь\n",
    "nltk.download('wordnet')\n",
    "print('')\n",
    "# создаём объект этого класса\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# и пустой список для слов после лемматизации\n",
    "lemmatized = []\n",
    "\n",
    "# проходимся по всем токенам\n",
    "for token in no_stops:\n",
    "    # применяем лемматизацию\n",
    "    token = lemmatizer.lemmatize(token)\n",
    "    # добавляем слово после лемматизации в список\n",
    "    lemmatized.append(token)\n",
    "\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. Стемминг (Приведение к основе)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница между лематизацией и стеммингом. \n",
    "\n",
    "Например, лемматизация правильно определила бы базовую форму «caring» и «care», в то время как стемминг отрезал бы «ing» и преобразовал ее в car.\n",
    "### «Caring» -> Лемматизация -> «Care»\n",
    "\n",
    "### «Caring» -> Стемминг -> «Car»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двумя наиболее популярными алгоритмами являются стеммер Портера и Snowball. Стеммер Портера назван в честь специалиста в области компьютерных наук Мартина Портера (Martin Porter)1. Портеру мы обязаны и усовершенствованной версией его стеммера под названием Snowball2. Мартин посвятил большую часть своей долгой карьеры документированию и улучшению стеммеров ввиду важности их роли в поиске информации (поиске по ключевым словам). Описанные выше стеммеры реализуют более сложные, чем обычные регулярные выражения, правила. Это позволяет справляться со сложностями правил правописания и окончания слов английского языка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pari', 'visit', 'lot', 'museum', 'first', 'went', 'louvr', 'largest', 'art', 'museum', 'world', 'alway', 'interest', 'art', 'spent', 'mani', 'hour', 'museum', 'enourm', 'week', 'would', 'enough']\n"
     ]
    }
   ],
   "source": [
    "# импортируем класс стеммера Porter и создаём объект этого класса\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# используем list comprehension вместо цикла for для стемминга и создание нового списка\n",
    "# такая запись намного короче\n",
    "stemmed_p = [porter.stem(s) for s in lemmatized]\n",
    "print(stemmed_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сценарии использования\n",
    "\n",
    "В каких случаях следует использовать лемматизатор, а в каких — стеммер? По-\n",
    "следние, как правило, работают быстрее и требуют менее сложного кода и мень-\n",
    "ших наборов данных. Однако они более подвержены ошибкам и сводят к одной основе гораздо большее количество слов, сокращая тем самым информационное\n",
    "содержание (смысл) текста намного сильнее, чем лемматизаторы. Обе технологии уменьшают размер словаря и увеличивают неоднозначность текста, однако лем-\n",
    "матизаторы работают лучше, сохраняя как можно больше полезной информации на основе применения слова в тексте и его желаемого смысла. Поэтому некоторые пакеты NLP, такие как spaCy, не включают функции для стемминга, а только ме-\n",
    "тоды для лемматизации.\n",
    "\n",
    "Если приложение связано с поиском информации, использование стемминга\n",
    "и лемматизации повысит его чувствительность и сопоставит тем же словам запроса\n",
    "больше документов. Тем не менее стемминг, лемматизация и выравнивание регистра\n",
    "значительно снижают точность результатов поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог\n",
    "\n",
    "Подводя итог сказанному выше, хочется попросить максимально избегать ис-\n",
    "пользования стемминга и лемматизации, за исключением небольших текстов,\n",
    "содержащих искомые слова в различном регистре. Учитывая лавинообразный\n",
    "рост размеров наборов данных NLP, такое редко имеет место для документов на английском языке, разве что тексты изобилуют жаргонизмами или относятся к очень узкой области науки, техники или литературы. Впрочем,\n",
    "для текстов, написанных на отличных от английского языках, лемматизация\n",
    "все еще может принести пользу. Стэнфордский курс по поиску информации\n",
    "целиком исключает стемминг и лемматизацию ввиду пренебрежимо малого\n",
    "увеличения чувствительности и сильного снижения уровня точности\n",
    "\n",
    "Функция для предобработки английского и русского текста (без стемминга):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_words_en = stopwords.words('english')\n",
    "stops_words_ru = stopwords.words('russian')\n",
    "\n",
    "def preprocess(text, stop_words):\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        t = word_tokenize(sentence)\n",
    "        tokens.extend(t)\n",
    "    no_stops = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        if token not in stop_words and token.isalpha():\n",
    "            no_stops.append(token)\n",
    "            \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "\n",
    "    for token in no_stops:\n",
    "        token = lemmatizer.lemmatize(token)\n",
    "        lemmatized.append(token)\n",
    "        \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['обманывая',\n",
       " 'человек',\n",
       " 'прежде',\n",
       " 'обманывает',\n",
       " 'самого',\n",
       " 'ибо',\n",
       " 'думает',\n",
       " 'успешно',\n",
       " 'соврал',\n",
       " 'люди',\n",
       " 'поняли',\n",
       " 'деликатности',\n",
       " 'промолчали',\n",
       " 'жизнь',\n",
       " 'прежде',\n",
       " 'творчество',\n",
       " 'это',\n",
       " 'значит',\n",
       " 'каждый',\n",
       " 'человек',\n",
       " 'жить',\n",
       " 'должен',\n",
       " 'родиться',\n",
       " 'художником',\n",
       " 'балериной',\n",
       " 'ученым',\n",
       " 'творить',\n",
       " 'просто',\n",
       " 'добрую',\n",
       " 'атмосферу',\n",
       " 'вокруг',\n",
       " 'человек',\n",
       " 'принести',\n",
       " 'собой',\n",
       " 'атмосферу',\n",
       " 'подозрительности',\n",
       " 'тягостного',\n",
       " 'молчания',\n",
       " 'внести',\n",
       " 'сразу',\n",
       " 'радость',\n",
       " 'свет',\n",
       " 'это',\n",
       " 'творчество']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ru = '''Обманывая, человек прежде всего обманывает самого себя, ибо он думает, что успешно соврал, а люди поняли и из деликатности промолчали. \n",
    "Жизнь - прежде всего творчество, но это не значит, что каждый человек, чтобы жить, должен родиться художником, балериной или ученым. \n",
    "Можно творить просто добрую атмосферу вокруг себя. Человек может принести с собой атмосферу подозрительности, какого-то тягостного молчания, а может внести сразу радость, свет. \n",
    "Вот это и есть творчество.'''\n",
    "preprocess(text_ru, stops_words_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thomas',\n",
       " 'jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'monticello',\n",
       " 'age',\n",
       " 'construction',\n",
       " 'done',\n",
       " 'mostly',\n",
       " 'local',\n",
       " 'mason',\n",
       " 'carpenter',\n",
       " 'moved',\n",
       " 'south',\n",
       " 'pavilion',\n",
       " 'turning',\n",
       " 'monticello',\n",
       " 'neoclassical',\n",
       " 'masterpiece',\n",
       " 'jefferson',\n",
       " 'obsession']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_en = '''Thomas Jefferson began building Monticello at the age of 26. \n",
    "Construction was done mostly by local masons and carpenters. \n",
    "He moved into the South Pavilion in 1770. \n",
    "Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.'''\n",
    "preprocess(text_en, stops_words_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешок слов (bag of words, BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('museum', 3), ('art', 2), ('paris', 1), ('visited', 1), ('lot', 1), ('first', 1), ('went', 1), ('louvre', 1), ('largest', 1), ('world', 1)]\n"
     ]
    }
   ],
   "source": [
    "# из модуля collections импортируем класс Counter\n",
    "from collections import Counter\n",
    "\n",
    "# применяем класс Counter к словам после лемматизации\n",
    "# на выходе нам возвращается словарь { слово : его частота в тексте }\n",
    "bow_counter = Counter(lemmatized)\n",
    "# print(bow_counter)\n",
    "\n",
    "# функция most_common() упорядочивает словарь по значению\n",
    "# посмотрим на первые 10 наиболее частотных слов\n",
    "print(bow_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем класс CountVectorizer из библиотеки Scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# создаём объект этого класса и\n",
    "# указываем, что хотим перевести слова в нижний регистр, а также\n",
    "# отфильтровать стоп-слова через stop_words = {'english'}\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             lowercase = True,\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = {'english'},\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# применяем этот объект к предложениям (ещё говорят документам)\n",
    "bow_cv = vectorizer.fit_transform(sentences)\n",
    "\n",
    "# на выходе получается матрица csr\n",
    "print(type(bow_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 2 0 0 1 1 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 3 0 1 0 1 0 1 0 0 1 0]\n",
      " [1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# преобразуем матрицу csr в привычный формат массива Numpy\n",
    "# для этого можно использовать .toarray()\n",
    "print(bow_cv.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 34)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строки это предложения (документы), столбцы - слова (токены)\n",
    "bow_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'when': 31, 'we': 27, 'were': 30, 'in': 9, 'paris': 20, 'visited': 26, 'lot': 13, 'of': 19, 'museums': 17, 'first': 6, 'went': 29, 'to': 25, 'the': 23, 'louvre': 14, 'largest': 12, 'art': 1, 'museum': 16, 'world': 32, 'have': 7, 'always': 0, 'been': 3, 'interested': 10, 'so': 21, 'spent': 22, 'many': 15, 'hours': 8, 'there': 24, 'is': 11, 'enourmous': 5, 'week': 28, 'would': 33, 'not': 18, 'be': 2, 'enough': 4}\n",
      "['always' 'art' 'be' 'been' 'enough' 'enourmous' 'first' 'have' 'hours'\n",
      " 'in' 'interested' 'is' 'largest' 'lot' 'louvre' 'many' 'museum' 'museums'\n",
      " 'not' 'of' 'paris' 'so' 'spent' 'the' 'there' 'to' 'visited' 'we' 'week'\n",
      " 'went' 'were' 'when' 'world' 'would']\n"
     ]
    }
   ],
   "source": [
    "# мы можем посмотреть на используемые токены (слова)\n",
    "\n",
    "# здесь числа это не частотность, а просто порядковый номер (индекс)\n",
    "vocab = vectorizer.vocabulary_\n",
    "print(vocab)\n",
    "\n",
    "# можно вывести слова и без индекса\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>always</th>\n",
       "      <th>art</th>\n",
       "      <th>be</th>\n",
       "      <th>been</th>\n",
       "      <th>enough</th>\n",
       "      <th>enourmous</th>\n",
       "      <th>first</th>\n",
       "      <th>have</th>\n",
       "      <th>hours</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>there</th>\n",
       "      <th>to</th>\n",
       "      <th>visited</th>\n",
       "      <th>we</th>\n",
       "      <th>week</th>\n",
       "      <th>went</th>\n",
       "      <th>were</th>\n",
       "      <th>when</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            always  art  be  been  enough  enourmous  first  have  hours  in  \\\n",
       "Sentence_0       0    0   0     0       0          0      0     0      0   1   \n",
       "Sentence_1       0    1   0     0       0          0      1     0      0   1   \n",
       "Sentence_2       1    1   0     1       0          0      0     1      1   1   \n",
       "Sentence_3       0    0   1     0       1          1      0     0      0   0   \n",
       "\n",
       "            ...  there  to  visited  we  week  went  were  when  world  would  \n",
       "Sentence_0  ...      0   0        1   2     0     0     1     1      0      0  \n",
       "Sentence_1  ...      0   1        0   1     0     1     0     0      1      0  \n",
       "Sentence_2  ...      1   0        0   0     0     0     0     0      0      0  \n",
       "Sentence_3  ...      1   0        0   0     1     0     0     0      0      1  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для удобства преобразуем матрицу в датафрейм\n",
    "# вначале создадим индекс предложений (документов)\n",
    "index_list = []\n",
    "\n",
    "# в цикле пройдемся по элементам матрицы, обозначим их через '_'\n",
    "# функция enumerate задаст каждому элементу индекс, начиная с 0\n",
    "for i, _ in enumerate(bow_cv):\n",
    "    # прибавим наш индекс к слову Sentence\n",
    "    index_list.append(f'Sentence_{i}')\n",
    "\n",
    "# print(index_list)\n",
    "\n",
    "# теперь можно использовать pd.DataFrame\n",
    "bow_cv_df = pd.DataFrame(data = bow_cv.toarray(),\n",
    "                         index = index_list,\n",
    "                         columns = tokens)\n",
    "bow_cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "#### Способ 1. CountVectorizer + TfidfTransformer\n",
    "\n",
    "1) Расчет TF, term frequency, частоты слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x34 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# этот шаг мы уже выполнили выше\n",
    "bow_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Теперь нужно рассчитать IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем TfidfTransformer (CountVectorizer уже импортирован)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# создадим объект класса TfidfTransformer\n",
    "tfidf_trans = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "\n",
    "# и рассчитаем IDF слов\n",
    "tfidf_trans.fit(bow_cv)\n",
    "\n",
    "# поместим результат в датафрейм\n",
    "df_idf = pd.DataFrame(tfidf_trans.idf_, index = tokens, columns = [\"idf_weights\"])\n",
    "#df_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) TF x IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x34 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рассчитаем TF-IDF (по сути умножим TF на IDF)\n",
    "tf_idf_vector = tfidf_trans.transform(bow_cv)\n",
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1         2         3\n",
      "always      0.000000  0.000000  0.328404  0.000000\n",
      "art         0.000000  0.211724  0.258918  0.000000\n",
      "be          0.000000  0.000000  0.000000  0.324676\n",
      "been        0.000000  0.000000  0.328404  0.000000\n",
      "enough      0.000000  0.000000  0.000000  0.324676\n",
      "enourmous   0.000000  0.000000  0.000000  0.324676\n",
      "first       0.000000  0.268544  0.000000  0.000000\n",
      "have        0.000000  0.000000  0.328404  0.000000\n",
      "hours       0.000000  0.000000  0.328404  0.000000\n",
      "in          0.202925  0.171408  0.209616  0.000000\n",
      "interested  0.000000  0.000000  0.328404  0.000000\n",
      "is          0.000000  0.000000  0.000000  0.324676\n",
      "largest     0.000000  0.268544  0.000000  0.000000\n",
      "lot         0.317921  0.000000  0.000000  0.000000\n",
      "louvre      0.000000  0.268544  0.000000  0.000000\n",
      "many        0.000000  0.000000  0.328404  0.000000\n",
      "museum      0.000000  0.211724  0.000000  0.255978\n",
      "museums     0.317921  0.000000  0.000000  0.000000\n",
      "not         0.000000  0.000000  0.000000  0.324676\n",
      "of          0.317921  0.000000  0.000000  0.000000\n",
      "paris       0.317921  0.000000  0.000000  0.000000\n",
      "so          0.000000  0.000000  0.258918  0.255978\n",
      "spent       0.000000  0.000000  0.328404  0.000000\n",
      "the         0.000000  0.635171  0.000000  0.255978\n",
      "there       0.000000  0.000000  0.258918  0.255978\n",
      "to          0.000000  0.268544  0.000000  0.000000\n",
      "visited     0.317921  0.000000  0.000000  0.000000\n",
      "we          0.501305  0.211724  0.000000  0.000000\n",
      "week        0.000000  0.000000  0.000000  0.324676\n",
      "went        0.000000  0.268544  0.000000  0.000000\n",
      "were        0.317921  0.000000  0.000000  0.000000\n",
      "when        0.317921  0.000000  0.000000  0.000000\n",
      "world       0.000000  0.268544  0.000000  0.000000\n",
      "would       0.000000  0.000000  0.000000  0.324676\n"
     ]
    }
   ],
   "source": [
    "# теперь мы можем посмотреть на показатель TF-IDF для конкретного слова в конкретном документе\n",
    "\n",
    "# для этого переведем матрицу csr в обычный массив Numpy\n",
    "df_tfidf = pd.DataFrame(tf_idf_vector.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "# и траспонируем его (запишем столбцы в виде строк)\n",
    "print(df_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим сколько слов оставил нам этот метод после обработки\n",
    "df_tfidf.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем класс TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем объект класса TfidfVectorizer\n",
    "tfIdfVectorizer = TfidfVectorizer(use_idf = True, stop_words= 'english')\n",
    "\n",
    "# сразу рассчитываем TF-IDF слов\n",
    "tfIdf = tfIdfVectorizer.fit_transform(sentences)\n",
    "tfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['art' 'enourmous' 'hours' 'interested' 'largest' 'lot' 'louvre' 'museum'\n",
      " 'museums' 'paris' 'spent' 'visited' 'week' 'went' 'world']\n"
     ]
    }
   ],
   "source": [
    "# можно посмотреть какие слова остались после фильтрации\n",
    "print(tfIdfVectorizer.get_feature_names_out())\n",
    "\n",
    "# например по сравнению со способом 1 выпало наречие always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51082562, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.51082562, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# также можно посмотреть IDF слов\n",
    "tfIdfVectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# через датафрейм мы можем связать слова и их IDF\n",
    "df_idf = pd.DataFrame(tfIdfVectorizer.idf_, index = tfIdfVectorizer.get_feature_names_out(), columns = ['idf_weights'])\n",
    "# df_idf.sort_values(by = 'idf_weights', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество предложений (документов) х количество слов\n",
    "tfIdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет значения TF-IDF для каждого слова по каждому тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3\n",
      "art         0.0  0.344315  0.414289  0.000000\n",
      "enourmous   0.0  0.000000  0.000000  0.617614\n",
      "hours       0.0  0.000000  0.525473  0.000000\n",
      "interested  0.0  0.000000  0.525473  0.000000\n",
      "largest     0.0  0.436719  0.000000  0.000000\n",
      "lot         0.5  0.000000  0.000000  0.000000\n",
      "louvre      0.0  0.436719  0.000000  0.000000\n",
      "museum      0.0  0.344315  0.000000  0.486934\n",
      "museums     0.5  0.000000  0.000000  0.000000\n",
      "paris       0.5  0.000000  0.000000  0.000000\n",
      "spent       0.0  0.000000  0.525473  0.000000\n",
      "visited     0.5  0.000000  0.000000  0.000000\n",
      "week        0.0  0.000000  0.000000  0.617614\n",
      "went        0.0  0.436719  0.000000  0.000000\n",
      "world       0.0  0.436719  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "# и наконец само значение TF-IDF для конкретного слова в конкретном документе\n",
    "# чем оно уникальнее для конкретного документа, тем выше показатель\n",
    "df_tfidf = pd.DataFrame(tfIdf.toarray(), columns = tfIdfVectorizer.get_feature_names_out())\n",
    "print(df_tfidf.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет среднего значения TF-IDF для каждого слова по всем текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.18965082, 0.15440359, 0.13136819, 0.13136819, 0.10917983,\n",
       "         0.125     , 0.10917983, 0.2078122 , 0.125     , 0.125     ,\n",
       "         0.13136819, 0.125     , 0.15440359, 0.10917983, 0.10917983]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рассчитаем среднее арифметическое по строкам (axis = 0)\n",
    "tfIdf.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18965082, 0.15440359, 0.13136819, 0.13136819, 0.10917983,\n",
       "        0.125     , 0.10917983, 0.2078122 , 0.125     , 0.125     ,\n",
       "        0.13136819, 0.125     , 0.15440359, 0.10917983, 0.10917983]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# преобразуем матрицу в массив Numpy\n",
    "np.asarray(tfIdf.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим сколько измерений\n",
    "np.asarray(tfIdf.mean(axis = 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18965082, 0.15440359, 0.13136819, 0.13136819, 0.10917983,\n",
       "       0.125     , 0.10917983, 0.2078122 , 0.125     , 0.125     ,\n",
       "       0.13136819, 0.125     , 0.15440359, 0.10917983, 0.10917983])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# уберем второе измерение\n",
    "np.asarray(tfIdf.mean(axis = 0)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# снова смотрим на размерность\n",
    "np.asarray(tfIdf.mean(axis = 0)).ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18965081782108964, 0.15440359274390048, 0.13136818731601646, 0.13136818731601646, 0.10917982746877804, 0.125, 0.10917982746877804, 0.2078121960479979, 0.125, 0.125, 0.13136818731601646, 0.125, 0.15440359274390048, 0.10917982746877804, 0.10917982746877804]\n"
     ]
    }
   ],
   "source": [
    "# преобразуем в список\n",
    "mean_weights = np.asarray(tfIdf.mean(axis = 0)).ravel().tolist()\n",
    "print(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>museum</td>\n",
       "      <td>0.207812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art</td>\n",
       "      <td>0.189651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enourmous</td>\n",
       "      <td>0.154404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>week</td>\n",
       "      <td>0.154404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours</td>\n",
       "      <td>0.131368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interested</td>\n",
       "      <td>0.131368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spent</td>\n",
       "      <td>0.131368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lot</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>museums</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paris</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term  mean_weights\n",
       "0      museum      0.207812\n",
       "1         art      0.189651\n",
       "2   enourmous      0.154404\n",
       "3        week      0.154404\n",
       "4       hours      0.131368\n",
       "5  interested      0.131368\n",
       "6       spent      0.131368\n",
       "7         lot      0.125000\n",
       "8     museums      0.125000\n",
       "9       paris      0.125000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаём датафрейм из словаря\n",
    "mean_weights_df = pd.DataFrame({'term': tfIdfVectorizer.get_feature_names_out(), 'mean_weights': mean_weights})\n",
    "\n",
    "# сортируем по убыванию 10 слов с максимальным средним TF-IDF\n",
    "mean_weights_df.sort_values(by = 'mean_weights', ascending = False).reset_index(drop = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Косинусное расстояние между текстовыми векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from scipy.sparse.csr import csr_matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.4261596  0.4261596  0.4261596  0.4261596  0.\n",
      "  0.4261596  0.30321606]\n",
      " [0.6316672  0.         0.         0.         0.         0.6316672\n",
      "  0.         0.44943642]]\n"
     ]
    }
   ],
   "source": [
    "# возьмем для простоты два текста (предложения)\n",
    "text1 = 'all the world’s a stage, and all the men and women merely players'\n",
    "text2 = 'you must be the change you wish to see in the world'\n",
    "\n",
    "# объединим их в корпус\n",
    "corpus = [text1, text2]\n",
    "\n",
    "# создадим объект класса TfidfVectorizer\n",
    "tfIdfVectorizer = TfidfVectorizer(use_idf = True, stop_words = 'english')\n",
    "\n",
    "# на выходе получаем два вектора, где каждое значение - это вес (показатель tf-idf) слова\n",
    "X = tfIdfVectorizer.fit_transform(corpus)\n",
    "\n",
    "# преобразуем данные формат массива Numpy\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change</th>\n",
       "      <th>men</th>\n",
       "      <th>merely</th>\n",
       "      <th>players</th>\n",
       "      <th>stage</th>\n",
       "      <th>wish</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vector1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.303216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vector2</th>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.449436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           change      men   merely  players    stage      wish    women  \\\n",
       "vector1  0.000000  0.42616  0.42616  0.42616  0.42616  0.000000  0.42616   \n",
       "vector2  0.631667  0.00000  0.00000  0.00000  0.00000  0.631667  0.00000   \n",
       "\n",
       "            world  \n",
       "vector1  0.303216  \n",
       "vector2  0.449436  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для удобства можем посмотреть на веса в формате датафрейма\n",
    "vectors_df = pd.DataFrame(data = X.toarray(),\n",
    "                          index = ['vector1', 'vector2'],\n",
    "                          columns = tfIdfVectorizer.get_feature_names_out())\n",
    "vectors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомню формулу косинусного расстояния:\n",
    "\n",
    "$$ \\cos(\\theta )={\\mathbf {a} \\cdot \\mathbf {b} \\over \\|\\mathbf {a} \\|\\|\\mathbf {b} \\|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем вектора по отдельности\n",
    "vector1 = X.toarray()[0]\n",
    "vector2 = X.toarray()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вначале выполним операции в числителе формулы\n",
    "numerator = np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь займемся знаменателем и\n",
    "# (1) рассчитаем длины (по большому счету, это теорема Пифагора)\n",
    "vector1Len = np.linalg.norm(vector1)\n",
    "vector2Len = np.linalg.norm(vector2)\n",
    "\n",
    "# (2) перемножим их\n",
    "denominator = vector1Len * vector2Len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13627634143908643"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим, чему равен косинус угла между векторами\n",
    "cosine = numerator/denominator\n",
    "cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.17"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# найдем угол в градусах по его косинусу\n",
    "# для этого вначале вычислим угол в радианах\n",
    "angle_radians = np.arccos(cosine)\n",
    "\n",
    "# затем в градусах\n",
    "angle_degrees = angle_radians * 360/2/np.pi\n",
    "round(angle_degrees, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кластерный анализ текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в тексте ниже две темы: наука о данных и Большой театр (источник: Википедия)\n",
    "text = '''\n",
    "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data.\n",
    "It applies knowledge and actionable insights from data across a broad range of application domains.\n",
    "Data science is related to data mining, machine learning and big data.\n",
    "The Bolshoi Theatre is a historic theatre in Moscow, Russia.\n",
    "It was originally designed by architect Joseph Bové, which holds ballet and opera performances.\n",
    "Before the October Revolution it was a part of the Imperial Theatres of the Russian Empire along with Maly Theatre in Moscow and a few theatres in Saint Petersburg.\n",
    "Data science is a concept to unify statistics, data analysis, informatics, and their related methods in order to understand and analyze actual phenomena with data.\n",
    "However, data science is different from computer science and information science.\n",
    "The main building of the theatre, rebuilt and renovated several times during its history, is a landmark of Moscow and Russia.\n",
    "On 28 October 2011, the Bolshoi re-opened after an extensive six-year renovation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим список из предложений\n",
    "corpus = []\n",
    "\n",
    "# для этого в цикле for пройдемся по тексту, разделив его по символу новой строки \\n\n",
    "for line in text.split('\\n'):\n",
    "\n",
    "  # если строка не пустая (т.е. True)\n",
    "  if line:\n",
    "\n",
    "    # переводим ее в нижний регистр\n",
    "    line = line.lower()\n",
    "    # и добавляем в список\n",
    "    corpus.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data.',\n",
       " 'it applies knowledge and actionable insights from data across a broad range of application domains.',\n",
       " 'data science is related to data mining, machine learning and big data.',\n",
       " 'the bolshoi theatre is a historic theatre in moscow, russia.',\n",
       " 'it was originally designed by architect joseph bové, which holds ballet and opera performances.',\n",
       " 'before the october revolution it was a part of the imperial theatres of the russian empire along with maly theatre in moscow and a few theatres in saint petersburg.',\n",
       " 'data science is a concept to unify statistics, data analysis, informatics, and their related methods in order to understand and analyze actual phenomena with data.',\n",
       " 'however, data science is different from computer science and information science.',\n",
       " 'the main building of the theatre, rebuilt and renovated several times during its history, is a landmark of moscow and russia.',\n",
       " 'on 28 october 2011, the bolshoi re-opened after an extensive six-year renovation.']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим TfidfVectorizer\n",
    "tfIdfVectorizer = TfidfVectorizer(use_idf = True, stop_words= 'english')\n",
    "\n",
    "# на выходе получаем векторы предложений\n",
    "X = tfIdfVectorizer.fit_transform(corpus)\n",
    "# print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем алгоритм k-средних из библиотеки sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# так как мы знаем, что темы две, используем гиперпараметр k = 2\n",
    "kmeans = KMeans(n_clusters = 2).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем новые предложения, одно из области Data Science и два про Большой театр\n",
    "prediction = ['Many statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics.',\n",
    "              'Urusov set up the theatre in collaboration with English tightrope walker Michael Maddox.',\n",
    "              'Until the mid-1990s, most foreign operas were sung in Russian, but Italian and other languages have been heard more frequently on the Bolshoi stage in recent years.']\n",
    "\n",
    "# применим две модели, сначала создадим векторы новых предложений (tfIdfVectorizer.transform),\n",
    "# затем отнесем их к одному из кластеров (kmeans.predict)\n",
    "kmeans.predict(tfIdfVectorizer.transform(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плотные векторные представления слов\n",
    "## Word2Vec\n",
    "### Предварительно обученные векторы Word2Vec для английского и русского языков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "word2vec_eng = gensim.downloader.load('word2vec-google-news-300')\n",
    "word2vec_rus = gensim.downloader.load('word2vec-ruscorpora-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.42578125e-01, -3.68652344e-02,  1.35742188e-01, -6.20117188e-02,\n",
       "        7.95898438e-02,  1.90429688e-02, -8.15429688e-02, -1.27929688e-01,\n",
       "       -2.95410156e-02,  2.36328125e-01, -1.21582031e-01, -2.14843750e-01,\n",
       "        1.29882812e-01, -2.70996094e-02, -5.20019531e-02,  2.15820312e-01,\n",
       "       -1.81640625e-01,  5.10253906e-02, -1.60156250e-01, -1.76757812e-01,\n",
       "        1.83105469e-02, -4.12597656e-02, -2.32421875e-01, -1.03149414e-02,\n",
       "        1.45507812e-01,  5.24902344e-02, -3.96484375e-01, -1.92871094e-02,\n",
       "        2.51770020e-03, -1.26953125e-02, -4.39453125e-02,  3.07617188e-02,\n",
       "        9.57031250e-02, -1.75781250e-01,  1.04370117e-02,  1.89453125e-01,\n",
       "       -2.36328125e-01,  4.37011719e-02,  2.81250000e-01, -2.07519531e-02,\n",
       "       -1.81640625e-01, -2.17773438e-01,  2.33398438e-01,  5.29785156e-02,\n",
       "       -1.13769531e-01,  9.39941406e-03, -1.49414062e-01,  1.99218750e-01,\n",
       "       -1.75781250e-01,  3.16406250e-01,  8.10546875e-02, -6.12792969e-02,\n",
       "       -1.52343750e-01, -1.81884766e-02,  8.25195312e-02,  8.74023438e-02,\n",
       "       -1.18652344e-01, -2.59765625e-01, -1.68457031e-02,  1.87988281e-02,\n",
       "        1.36108398e-02, -2.39257812e-01, -6.78710938e-02, -8.15429688e-02,\n",
       "        2.18750000e-01,  6.64062500e-02,  1.27929688e-01,  1.64062500e-01,\n",
       "        2.28271484e-02, -1.38671875e-01, -9.42382812e-02,  3.51562500e-02,\n",
       "        7.37304688e-02, -1.06445312e-01,  1.47705078e-02, -6.15234375e-02,\n",
       "        2.48046875e-01,  9.22851562e-02,  1.45263672e-02,  2.92968750e-01,\n",
       "        2.47070312e-01, -3.46679688e-02, -1.92382812e-01,  2.28881836e-03,\n",
       "        1.33789062e-01,  5.05371094e-02, -1.56250000e-01,  2.02148438e-01,\n",
       "       -3.39355469e-02, -1.10351562e-01,  1.31835938e-02, -1.84570312e-01,\n",
       "        6.73828125e-02,  9.22851562e-02,  2.70996094e-02,  1.44653320e-02,\n",
       "        7.37304688e-02, -1.96289062e-01,  6.39648438e-02,  1.46484375e-01,\n",
       "        3.67187500e-01, -3.67187500e-01,  1.13281250e-01, -5.66406250e-02,\n",
       "        5.27343750e-02, -1.66015625e-01,  1.59179688e-01, -1.28906250e-01,\n",
       "        2.21679688e-01,  1.07910156e-01,  1.56250000e-01,  2.65625000e-01,\n",
       "       -1.50390625e-01,  6.83593750e-02,  2.08984375e-01, -1.70898438e-02,\n",
       "       -1.38671875e-01,  3.26171875e-01,  2.37304688e-01, -9.03320312e-02,\n",
       "        9.27734375e-03, -8.59375000e-02, -1.22558594e-01,  1.12792969e-01,\n",
       "        1.17187500e-01, -3.32031250e-02,  1.62109375e-01, -1.33789062e-01,\n",
       "        1.45507812e-01, -8.64257812e-02, -9.13085938e-02, -5.37109375e-02,\n",
       "       -7.91015625e-02, -8.48388672e-03, -1.78710938e-01, -8.66699219e-03,\n",
       "        4.12109375e-01,  8.34960938e-02, -2.67578125e-01,  4.02832031e-02,\n",
       "       -6.64062500e-02,  8.74023438e-02, -1.87500000e-01, -9.37500000e-02,\n",
       "       -8.98437500e-02,  6.49414062e-02,  1.74804688e-01, -1.85546875e-01,\n",
       "       -1.49414062e-01, -2.10937500e-01,  1.25976562e-01, -7.47070312e-02,\n",
       "       -1.94335938e-01, -1.91650391e-02, -1.89453125e-01, -1.84570312e-01,\n",
       "       -1.90429688e-01, -1.37695312e-01, -9.03320312e-02, -2.01416016e-02,\n",
       "        3.88183594e-02,  9.13085938e-02,  2.55859375e-01, -1.35742188e-01,\n",
       "        5.78613281e-02, -1.85546875e-01,  4.58984375e-01,  1.18164062e-01,\n",
       "        4.40597534e-04, -4.90722656e-02,  6.25000000e-02,  1.10839844e-01,\n",
       "       -1.93359375e-01, -2.59765625e-01,  1.83593750e-01,  1.99218750e-01,\n",
       "       -1.17187500e-01, -1.66992188e-01, -1.43554688e-01,  7.44628906e-03,\n",
       "       -1.25976562e-01,  5.00488281e-02, -7.22656250e-02, -1.06201172e-02,\n",
       "        2.11914062e-01,  9.91210938e-02, -1.88476562e-01, -4.95605469e-02,\n",
       "        8.83789062e-02, -1.50203705e-05, -1.26953125e-01,  3.04687500e-01,\n",
       "        2.49023438e-02,  4.24194336e-03,  6.64062500e-02, -3.26171875e-01,\n",
       "        4.60937500e-01, -1.50390625e-01, -1.48437500e-01, -2.95410156e-02,\n",
       "        3.10546875e-01,  1.72851562e-01, -1.46484375e-01,  6.93359375e-02,\n",
       "       -1.37695312e-01, -5.20019531e-02, -1.91406250e-01, -3.49121094e-02,\n",
       "        1.97265625e-01, -2.34375000e-01,  9.08203125e-02,  3.24218750e-01,\n",
       "       -4.70703125e-01,  1.70898438e-02, -2.35351562e-01, -8.05664062e-02,\n",
       "        3.14453125e-01,  2.20947266e-02, -1.42578125e-01, -2.79541016e-02,\n",
       "       -2.24609375e-01,  2.69775391e-02,  2.65625000e-01, -3.80859375e-02,\n",
       "        2.61230469e-02,  1.71875000e-01, -8.59375000e-02,  7.76367188e-02,\n",
       "       -2.51464844e-02,  8.78906250e-02,  1.00708008e-02,  1.62353516e-02,\n",
       "        3.18359375e-01, -1.09375000e-01,  2.85156250e-01,  1.00097656e-01,\n",
       "       -3.06396484e-02,  3.68652344e-02,  1.30859375e-01,  1.59179688e-01,\n",
       "       -1.11328125e-01,  4.45556641e-03, -3.44238281e-02, -7.71484375e-02,\n",
       "       -2.11181641e-02, -2.12890625e-01, -1.24023438e-01, -1.15356445e-02,\n",
       "        6.49414062e-02, -1.85546875e-02, -2.00195312e-01, -2.48046875e-01,\n",
       "        9.22851562e-02, -1.48437500e-01, -6.93359375e-02,  5.79833984e-03,\n",
       "       -3.41796875e-02,  1.44531250e-01, -9.37500000e-02,  1.26953125e-01,\n",
       "       -4.15039062e-02,  3.16406250e-01, -7.03125000e-02,  4.95605469e-02,\n",
       "        1.95312500e-01,  1.89208984e-02,  1.09863281e-02, -7.47070312e-02,\n",
       "       -1.28906250e-01, -1.29882812e-01,  1.03027344e-01,  8.00781250e-02,\n",
       "        6.25610352e-03,  1.40991211e-02, -1.43554688e-01,  1.36108398e-02,\n",
       "       -4.63867188e-02, -3.22265625e-01, -8.59375000e-02, -1.56250000e-01,\n",
       "        1.46484375e-01,  2.16796875e-01,  1.81640625e-01, -1.22070312e-01,\n",
       "       -2.30468750e-01, -1.92871094e-02, -1.26953125e-02,  1.09863281e-01,\n",
       "       -1.59179688e-01,  1.17675781e-01,  5.29785156e-02,  2.08984375e-01,\n",
       "       -1.37695312e-01,  1.62109375e-01, -1.72851562e-01,  3.63769531e-02,\n",
       "       -1.25976562e-01, -1.44653320e-02, -1.26953125e-01, -2.59765625e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим векторное представление для слова test\n",
    "word2vec_eng['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/184973 is весь_DET\n",
      "word #1/184973 is человек_NOUN\n",
      "word #2/184973 is мочь_VERB\n",
      "word #3/184973 is год_NOUN\n",
      "word #4/184973 is сказать_VERB\n",
      "word #5/184973 is время_NOUN\n",
      "word #6/184973 is говорить_VERB\n",
      "word #7/184973 is становиться_VERB\n",
      "word #8/184973 is знать_VERB\n",
      "word #9/184973 is самый_DET\n",
      "word #10/184973 is дело_NOUN\n",
      "word #11/184973 is день_NOUN\n",
      "word #12/184973 is жизнь_NOUN\n",
      "word #13/184973 is рука_NOUN\n",
      "word #14/184973 is очень_ADV\n",
      "word #15/184973 is первый_ADJ\n",
      "word #16/184973 is давать_VERB\n",
      "word #17/184973 is новый_ADJ\n",
      "word #18/184973 is слово_NOUN\n",
      "word #19/184973 is иметь_VERB\n"
     ]
    }
   ],
   "source": [
    "# какие слова есть в русском словаре \n",
    "for index, word in enumerate(word2vec_rus.index_to_key ):\n",
    "    if index == 20:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(word2vec_rus.index_to_key )} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.18535755e-02, -1.36514874e-02,  6.48699515e-03,  4.94286232e-02,\n",
       "        4.72369529e-02,  2.99715698e-02,  1.84931476e-02,  5.63697964e-02,\n",
       "        9.00735930e-02,  4.98076454e-02, -1.42216729e-02, -1.19277993e-02,\n",
       "        4.64369878e-02, -2.20510038e-03, -5.23579530e-02,  6.86843460e-03,\n",
       "        2.47351658e-02, -2.94565707e-02, -3.43381912e-02, -6.68611825e-02,\n",
       "        2.16565677e-03, -3.44541185e-02,  5.10950834e-02,  3.39556672e-02,\n",
       "       -1.03159972e-01,  1.10369720e-01, -4.85999370e-03, -9.61249918e-02,\n",
       "       -4.24017571e-02, -6.25817403e-02,  7.29365274e-02, -3.05048935e-02,\n",
       "       -1.22691244e-01,  5.59408627e-02, -3.77330072e-02, -5.60487658e-02,\n",
       "        2.35838126e-02, -9.34875384e-03, -1.72916036e-02, -1.21203892e-01,\n",
       "        5.48743568e-02,  4.17090692e-02,  9.80748981e-02, -1.06346466e-01,\n",
       "       -2.49845888e-02, -9.09208506e-02,  7.08984062e-02,  2.82790884e-02,\n",
       "        5.33705652e-02,  1.25205163e-02,  1.88979451e-02,  1.18532305e-04,\n",
       "        5.06328084e-02,  4.57610562e-02,  1.78273637e-02,  8.54188763e-03,\n",
       "       -6.64679259e-02, -4.12932336e-02,  3.49916518e-02,  1.63530111e-02,\n",
       "       -6.19022176e-02,  6.07473515e-02,  1.01269461e-01, -3.46405059e-02,\n",
       "        4.32611210e-03, -7.28566647e-02, -1.00999825e-01,  8.27706456e-02,\n",
       "        9.40009207e-02, -5.53704128e-02, -2.02254448e-02,  2.91196555e-02,\n",
       "        1.53161241e-02, -4.34027426e-02,  1.97300930e-02,  1.54576218e-02,\n",
       "       -6.13274686e-02,  2.06113071e-03,  1.13851897e-01, -7.34868869e-02,\n",
       "       -1.60414651e-02,  8.48944411e-02, -7.45684952e-02,  2.67308373e-02,\n",
       "       -3.62738036e-02,  2.92235538e-02,  1.38367247e-02,  8.71656388e-02,\n",
       "        5.27464077e-02,  1.09950090e-02, -1.83780156e-02,  6.22998178e-02,\n",
       "       -3.12038902e-02, -5.20598097e-03,  2.75466777e-02, -4.94646579e-02,\n",
       "        6.27711490e-02, -3.50464098e-02, -2.99848262e-02,  6.24796860e-02,\n",
       "        4.75758091e-02,  2.70669889e-02,  3.71761550e-03,  3.37163508e-02,\n",
       "       -1.59364194e-02,  5.16331680e-02,  3.53041068e-02, -2.24810001e-02,\n",
       "       -7.29505718e-02,  6.50355592e-02,  1.08175725e-01,  1.87114794e-02,\n",
       "        5.56157529e-03, -1.34880971e-02, -6.59002662e-02, -1.53818205e-01,\n",
       "       -6.40059263e-02, -6.35282043e-03, -2.79694498e-02,  1.12022266e-01,\n",
       "       -2.28945632e-02,  1.82572361e-02, -8.15376043e-05,  7.53166750e-02,\n",
       "        6.14850223e-03,  2.84064678e-03,  1.56548433e-02, -7.42037594e-02,\n",
       "       -1.87065580e-03,  1.42472098e-02,  2.42906548e-02, -5.27421907e-02,\n",
       "       -3.31688789e-03, -1.33249508e-02,  1.37140015e-02,  5.09426333e-02,\n",
       "       -2.61565540e-02, -7.37493187e-02,  1.12350613e-01,  7.26311803e-02,\n",
       "       -2.03162916e-02, -5.86216934e-02,  4.95063290e-02, -4.36895853e-03,\n",
       "       -6.48360997e-02, -4.47178222e-02, -5.67803122e-02, -4.27367724e-02,\n",
       "       -4.60596681e-02,  9.95943248e-02, -1.40637690e-02,  2.56624236e-03,\n",
       "       -2.56735776e-02,  1.59311518e-02,  1.58109032e-02,  5.23563065e-02,\n",
       "       -6.56011328e-02,  1.30699947e-02, -3.94459143e-02,  3.77264284e-02,\n",
       "        1.96559355e-02,  1.22658182e-02, -2.56576948e-02,  6.55936543e-03,\n",
       "        3.09303384e-02, -1.21158116e-01,  6.08079396e-02,  6.91229552e-02,\n",
       "        1.92254242e-02, -6.36561681e-03, -3.68151851e-02, -4.93471101e-02,\n",
       "       -1.83183439e-02,  2.50221640e-02,  7.94178173e-02,  4.22771983e-02,\n",
       "        1.14361234e-01, -4.45917286e-02, -7.48661533e-02,  4.11708094e-02,\n",
       "       -7.94917624e-03,  5.04709780e-02,  2.92948950e-02,  4.80987038e-03,\n",
       "        1.53637864e-02,  2.65616458e-02,  4.06131186e-02, -1.82010848e-02,\n",
       "        6.56814454e-03, -9.74708889e-03,  7.54194185e-02,  1.13135409e-02,\n",
       "       -7.18064187e-03, -1.36771575e-01,  5.79138920e-02,  1.53128728e-02,\n",
       "        7.27865621e-02, -6.25718981e-02, -1.81293916e-02, -2.02108473e-02,\n",
       "       -9.78578161e-03, -5.85023686e-02, -1.06884189e-01, -8.35147202e-02,\n",
       "        3.83248478e-02, -9.78319570e-02,  4.50908616e-02,  4.13148180e-02,\n",
       "        5.46393730e-02,  8.02896768e-02, -5.28243836e-03,  5.18167764e-02,\n",
       "        2.92067900e-02, -3.76904495e-02,  5.22531942e-02, -2.21717171e-03,\n",
       "       -1.05959944e-01,  8.27732757e-02,  3.50791663e-02,  8.09004456e-02,\n",
       "       -6.36590645e-04, -1.22129090e-01, -8.93137604e-03, -3.16960923e-02,\n",
       "       -7.25365418e-04, -3.85852680e-02,  1.43302754e-01,  1.66424468e-01,\n",
       "       -2.18346156e-02,  7.41368607e-02,  2.07344629e-03, -1.19717885e-02,\n",
       "        6.54021576e-02, -9.06530172e-02, -1.70140639e-02, -1.90422428e-03,\n",
       "        1.93148218e-02,  5.90180792e-02, -6.42528012e-02, -1.01350784e-01,\n",
       "        5.05384244e-02, -3.06491181e-02, -6.39107227e-02, -7.70654157e-02,\n",
       "       -6.67643473e-02, -8.93345699e-02,  4.56026308e-02, -9.87746008e-03,\n",
       "        5.10909148e-02, -2.91103888e-02, -8.33503902e-02, -1.55859798e-01,\n",
       "       -1.07718647e-01,  1.17454164e-01, -3.54383364e-02, -5.18609956e-02,\n",
       "        8.01040530e-02,  2.60616876e-02,  1.14487313e-01, -1.21907443e-01,\n",
       "       -3.40905860e-02,  1.62199344e-02,  4.94212704e-03,  3.59918550e-03,\n",
       "       -4.62557785e-02, -3.50834080e-03, -7.13766962e-02, -6.67815655e-02,\n",
       "       -7.48350173e-02, -7.09685460e-02,  4.05638888e-02, -7.85547681e-03,\n",
       "        5.94981946e-02,  1.58532783e-01, -4.43134084e-03,  4.21016030e-02,\n",
       "        5.20916842e-03,  8.61019716e-02,  8.14645290e-02,  3.92781645e-02,\n",
       "        7.01978861e-04,  2.47761160e-02, -4.07037744e-03,  7.70073524e-03,\n",
       "        6.63259029e-02,  4.75829914e-02, -1.13050081e-01, -9.66524035e-02,\n",
       "       -5.41707389e-02, -4.82660830e-02,  3.48761603e-02,  2.14750748e-02,\n",
       "        1.99396499e-02, -6.26251148e-03, -3.90144251e-02, -3.70639339e-02,\n",
       "        5.68427779e-02,  8.67086556e-03, -2.64839865e-02,  8.93315375e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# векторное представление для слова печь (глагол)\n",
    "word2vec_rus['печь_VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.04111098e-03,  3.17178331e-02,  5.26587218e-02, -2.81463489e-02,\n",
       "        3.36806215e-02, -1.19832382e-02,  6.69362992e-02,  5.34342714e-02,\n",
       "        7.75137171e-02,  5.08050360e-02,  3.30233364e-03, -2.16485690e-02,\n",
       "        5.27435094e-02,  1.38199255e-02, -7.34620243e-02, -2.33334582e-02,\n",
       "        3.33712399e-02,  3.48375104e-02,  3.63502614e-02, -4.44506891e-02,\n",
       "        1.17149157e-02, -4.02530469e-02, -6.20140284e-02,  7.47649819e-02,\n",
       "       -3.94869968e-02, -4.06278297e-02, -8.34002271e-02, -6.80526569e-02,\n",
       "       -1.62618563e-01, -5.65643683e-02,  1.65630854e-03, -1.48861082e-02,\n",
       "       -3.62066291e-02,  3.73510309e-02, -2.62216832e-02, -3.96667421e-02,\n",
       "       -9.02666152e-03,  1.10610299e-01, -1.12228990e-01, -1.61341488e-01,\n",
       "        1.11707663e-02, -6.39451202e-03,  5.29266559e-02, -1.17891423e-01,\n",
       "       -8.77382420e-03, -2.01879211e-05,  9.10191685e-02,  2.39265133e-02,\n",
       "        7.54997283e-02, -1.52666410e-02,  5.74746467e-02, -5.05433492e-02,\n",
       "        2.91562006e-02, -2.17891969e-02, -1.18826572e-02,  2.85888854e-02,\n",
       "       -3.20446976e-02,  2.96555785e-03,  3.17520462e-02,  1.16738630e-03,\n",
       "       -2.16536708e-02,  5.83722889e-02,  6.53800443e-02,  6.35675788e-02,\n",
       "        2.80635208e-02, -6.41776249e-02, -1.26498640e-01,  8.25762451e-02,\n",
       "        3.15851420e-02, -3.93940099e-02, -5.52064516e-02, -1.59041118e-02,\n",
       "        2.40683798e-02,  6.62525743e-03, -8.66583269e-03,  1.19829066e-01,\n",
       "        2.87018158e-02, -6.45772740e-02,  7.43033066e-02,  1.62272155e-02,\n",
       "       -3.27399261e-02,  6.71804324e-02, -4.79972139e-02,  4.04317491e-02,\n",
       "       -6.73297271e-02,  5.70626669e-02,  9.62437913e-02,  2.46405769e-02,\n",
       "        5.61542511e-02, -6.44602478e-02, -8.09001550e-02, -4.24236432e-02,\n",
       "       -3.49754579e-02, -4.78550158e-02,  9.20150988e-03, -9.50316638e-02,\n",
       "        6.11935705e-02, -4.11194526e-02,  4.84425426e-02,  8.02363232e-02,\n",
       "       -6.13625869e-02, -7.99783133e-03, -2.67373361e-02,  4.65280116e-02,\n",
       "        7.90212862e-03,  1.94804035e-02, -4.03046310e-02, -1.23887043e-02,\n",
       "       -1.70104057e-02,  9.83887315e-02,  1.02254033e-01,  3.54129709e-02,\n",
       "       -7.97719583e-02,  9.44451764e-02, -6.88563958e-02, -4.42126393e-02,\n",
       "       -2.76700519e-02,  2.42714789e-02, -3.93242203e-02, -4.40083072e-03,\n",
       "        2.55758292e-03, -8.51852149e-02, -1.81281641e-02,  5.84258810e-02,\n",
       "        5.72437712e-04, -5.44678420e-02,  8.13683718e-02, -1.34916874e-02,\n",
       "       -1.58683769e-02,  3.09989993e-02,  6.98299287e-03,  7.38396356e-03,\n",
       "       -7.00684935e-02, -8.35377052e-02,  5.68305328e-02, -4.42534909e-02,\n",
       "        5.82362106e-03, -1.66865308e-02, -6.68002814e-02,  3.68540250e-02,\n",
       "        6.68364093e-02,  8.42661932e-02,  4.13846001e-02,  6.33820221e-02,\n",
       "        5.23009971e-02, -2.99671330e-02, -4.35775667e-02,  2.96452232e-02,\n",
       "       -8.07212740e-02,  1.16212226e-01,  3.74425612e-02,  5.80590181e-02,\n",
       "        5.43325357e-02,  1.58263892e-02, -2.55084895e-02, -3.66843678e-02,\n",
       "        1.95723940e-02, -1.03710607e-01, -2.00209543e-02, -7.46546537e-02,\n",
       "       -6.20409325e-02, -6.22586049e-02, -7.71120936e-02,  4.36983258e-02,\n",
       "        1.94925219e-02, -1.01120956e-01, -2.13958360e-02,  3.57672907e-02,\n",
       "        3.44690820e-03,  3.50604132e-02,  6.27830699e-02, -1.28587976e-01,\n",
       "       -4.46029417e-02,  3.90188433e-02,  9.91340727e-02,  1.53278485e-01,\n",
       "        8.53673667e-02, -5.91412149e-02, -6.21093251e-02,  1.17255161e-02,\n",
       "        5.28062582e-02,  5.82912751e-02,  7.34764934e-02,  4.62218150e-02,\n",
       "        7.97192082e-02, -1.79783013e-02,  5.34338616e-02, -1.95229203e-02,\n",
       "       -8.93774778e-02,  1.82796922e-02,  6.00929782e-02,  8.36889744e-02,\n",
       "       -3.69432606e-02, -8.39514807e-02,  6.30876794e-02, -1.28500862e-02,\n",
       "       -1.21133146e-03, -9.34535861e-02, -4.93608825e-02, -4.90113273e-02,\n",
       "       -2.25747246e-02, -5.46448566e-02, -1.35820806e-01, -1.54009033e-02,\n",
       "       -5.95361553e-02, -1.63800403e-01, -1.22875012e-02,  1.06482416e-01,\n",
       "        6.07103156e-03, -5.12871891e-03,  1.98991708e-02, -7.69749982e-03,\n",
       "        4.29828130e-02,  1.55742029e-02,  2.85588466e-02,  5.05802222e-02,\n",
       "       -6.19536173e-03,  7.10553676e-02,  3.58315334e-02,  1.27903167e-02,\n",
       "       -7.35795796e-02, -1.15166157e-02,  1.90748628e-02, -2.27816384e-02,\n",
       "        7.04118144e-03, -1.25415623e-01,  4.86680306e-02,  1.20324492e-01,\n",
       "       -1.90788805e-02,  1.72033869e-02,  5.23368232e-02, -5.04792817e-02,\n",
       "        5.86587824e-02, -4.88322116e-02, -1.10781007e-02, -3.36438674e-03,\n",
       "        2.62496769e-02,  5.52049913e-02, -1.75047126e-02, -2.67160442e-02,\n",
       "        6.62052855e-02,  2.21071336e-02, -5.72599284e-02,  5.97622655e-02,\n",
       "        7.50152767e-02, -9.20058321e-03,  8.34535062e-02,  1.37469135e-02,\n",
       "        7.07960427e-02,  1.64752994e-02, -1.16385892e-01, -7.28768157e-03,\n",
       "       -9.54352096e-02,  8.52974951e-02, -1.07891314e-01,  5.46240024e-02,\n",
       "        1.18708938e-01,  9.56188329e-03,  1.27080768e-01, -4.77623157e-02,\n",
       "       -3.35567519e-02, -3.73203382e-02, -4.01373394e-02, -1.25895152e-02,\n",
       "       -3.66865620e-02,  2.44657304e-02,  2.79945973e-02,  1.26880845e-02,\n",
       "       -1.08274594e-01, -8.33899602e-02,  4.39459682e-02, -3.44437957e-02,\n",
       "       -8.40049889e-03,  1.08315177e-01, -2.27933247e-02, -2.37453077e-02,\n",
       "       -4.11164798e-02,  7.11826533e-02,  8.41675103e-02,  1.14128226e-02,\n",
       "       -3.97583768e-02, -1.64128430e-02,  8.25809781e-03, -9.04217246e-04,\n",
       "        3.18587013e-02,  1.96749121e-02, -4.55804206e-02, -3.58253345e-02,\n",
       "       -4.70046699e-02, -1.14834104e-02, -2.76539382e-02,  6.40464760e-03,\n",
       "        6.15377794e-04,  7.02709146e-03, -2.34442819e-02,  1.78269669e-03,\n",
       "        8.66848007e-02, -1.14074059e-01,  2.67470675e-03,  1.99027956e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# векторное представление для слова печь (существительное)\n",
    "word2vec_rus['печь_NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем найти наиболее похожие слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('печка_NOUN', 0.8358493447303772),\n",
       " ('подтопок_NOUN', 0.7017349600791931),\n",
       " ('печной_ADJ', 0.6326410174369812),\n",
       " ('полати_NOUN', 0.6188919544219971),\n",
       " ('топиться_VERB', 0.6180375814437866),\n",
       " ('горнушка_NOUN', 0.6172196865081787),\n",
       " ('топиться::по-черному_VERB', 0.6171698570251465),\n",
       " ('истапливать_VERB', 0.6131374835968018),\n",
       " ('топка_NOUN', 0.6026756763458252),\n",
       " ('печурка_NOUN', 0.6010895371437073)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_rus.most_similar(['печь_NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('напекать_VERB', 0.6473735570907593),\n",
       " ('испечь_VERB', 0.6360713243484497),\n",
       " ('жарить_VERB', 0.629960834980011),\n",
       " ('нардек_NOUN', 0.5905025005340576),\n",
       " ('выпекать_VERB', 0.5834865570068359),\n",
       " ('яшный_ADJ', 0.5677016377449036),\n",
       " ('варить_VERB', 0.5661610960960388),\n",
       " ('пирог_NOUN', 0.5652977228164673),\n",
       " ('тандыр_NOUN', 0.5573609471321106),\n",
       " ('месить::тесто_VERB', 0.5557463765144348)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_rus.most_similar(['печь_VERB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобученные моедли доступные в gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext-wiki-news-subwords-300',\n",
       " 'conceptnet-numberbatch-17-06-300',\n",
       " 'word2vec-ruscorpora-300',\n",
       " 'word2vec-google-news-300',\n",
       " 'glove-wiki-gigaword-50',\n",
       " 'glove-wiki-gigaword-100',\n",
       " 'glove-wiki-gigaword-200',\n",
       " 'glove-wiki-gigaword-300',\n",
       " 'glove-twitter-25',\n",
       " 'glove-twitter-50',\n",
       " 'glove-twitter-100',\n",
       " 'glove-twitter-200',\n",
       " '__testing_word2vec-matrix-synopsis']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 3930, done.\u001b[K\n",
      "remote: Counting objects: 100% (1003/1003), done.\u001b[K\n",
      "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
      "remote: Total 3930 (delta 912), reused 861 (delta 861), pack-reused 2927\u001b[K\n",
      "Receiving objects: 100% (3930/3930), 8.24 MiB | 15.24 MiB/s, done.\n",
      "Resolving deltas: 100% (2506/2506), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing /content/fastText\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from fasttext==0.9.2) (67.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fasttext==0.9.2) (1.22.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-linux_x86_64.whl size=4381799 sha256=b1e5434f111b8dbf915cac6a8d454ba935f83234c7be9a178edd5da3e00a8a88\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5uwdlvj8/wheels/2d/3b/6c/b1dab8ae56dbff3fc7c26103ce1f0646f1a39f6a06db46db46\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
     ]
    }
   ],
   "source": [
    "!cd fastText; pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка предварительно обученных векторных представлений fastText для русского языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cc.ru.300.bin'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fasttext.util.download_model('ru', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показываем векторы для слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58141226e-01,  1.40892416e-01, -1.16081268e-01, -3.65050286e-02,\n",
       "        1.24294966e-01,  3.56620317e-03,  1.00102514e-01, -5.51618822e-03,\n",
       "       -1.54162765e-01, -2.05441654e-01, -1.23218819e-01,  7.57891387e-02,\n",
       "        3.42986137e-02, -4.14514728e-02, -4.02112976e-02,  2.98824906e-02,\n",
       "       -5.66644147e-02,  8.71236175e-02,  4.90642563e-02,  1.29385591e-01,\n",
       "        1.04177101e-02, -1.39765948e-01,  1.96572430e-02,  9.35998783e-02,\n",
       "        2.53893584e-02, -8.46895576e-02, -2.33695209e-01, -9.06276107e-02,\n",
       "       -3.56095424e-03,  1.33594170e-01,  1.00002609e-01, -1.07181132e-01,\n",
       "        4.29465696e-02,  5.93492389e-03, -7.90850967e-02,  3.64862420e-02,\n",
       "        1.04223136e-02, -1.24680214e-01, -1.95677444e-01, -5.12315333e-02,\n",
       "        1.05863772e-01, -2.60896739e-02,  1.22163713e-01,  5.37529886e-02,\n",
       "        4.78603020e-02,  1.70780927e-01,  2.17139110e-01, -1.11144893e-01,\n",
       "        8.68928060e-02,  1.47899717e-01,  1.56384453e-01,  1.39447808e-01,\n",
       "       -4.18573767e-02,  8.52167010e-02, -2.96145137e-02,  6.71668649e-02,\n",
       "       -2.40663420e-02,  8.39635730e-04, -7.40315542e-02, -5.67587428e-02,\n",
       "       -2.12356504e-02, -8.23956802e-02, -6.93622455e-02, -3.01340874e-02,\n",
       "       -1.34806246e-01,  1.73259284e-02,  8.55030492e-03,  1.26894474e-01,\n",
       "        1.29043892e-01, -1.04056433e-01, -4.96997833e-02, -1.08139955e-01,\n",
       "       -1.13896012e-01,  1.01289809e-01, -3.47440913e-02,  1.36936307e-01,\n",
       "        2.03805789e-01, -2.43696701e-02,  5.68451993e-02,  8.22584406e-02,\n",
       "        7.84374550e-02,  1.56862270e-02, -3.75383012e-02, -8.03061053e-02,\n",
       "       -6.71014637e-02,  7.39557073e-02, -2.93304324e-01, -4.20905417e-03,\n",
       "       -3.72963175e-02, -1.63766295e-02, -9.77286100e-02,  2.11984083e-01,\n",
       "       -3.57807428e-03,  2.54601836e-01,  6.75749555e-02, -3.39750238e-02,\n",
       "       -6.88198805e-02, -8.40583351e-03,  6.26952276e-02,  4.34605144e-02,\n",
       "       -1.59511462e-01, -4.57643345e-02, -7.83522651e-02,  2.88255140e-02,\n",
       "       -2.66770311e-02, -1.56642869e-02,  5.17519116e-02,  3.38422433e-02,\n",
       "       -7.46595338e-02, -6.60877898e-02, -1.69584244e-01,  2.24096328e-01,\n",
       "        9.92211103e-02,  9.17259902e-02, -1.83744878e-02, -9.07710195e-02,\n",
       "       -1.28438592e-01,  2.13461071e-02,  1.01833818e-02,  1.21310890e-01,\n",
       "        1.04017407e-01,  9.60132405e-02,  6.15402758e-02, -1.99484333e-04,\n",
       "        8.25056881e-02,  7.06186444e-02, -6.74678385e-03,  6.57259375e-02,\n",
       "       -1.29938304e-01,  8.18681121e-02, -2.03595281e-01,  3.19921523e-02,\n",
       "       -1.90547511e-01,  1.56865731e-01, -8.08076710e-02,  1.50806177e-03,\n",
       "       -5.64649701e-04,  1.19535200e-01,  1.23776667e-01, -1.05378799e-01,\n",
       "        1.66345581e-01,  6.90696388e-02,  7.47753158e-02, -4.25944328e-02,\n",
       "       -4.99800704e-02, -2.22958595e-01, -3.49778794e-02,  1.63722895e-02,\n",
       "        7.34095722e-02, -8.56932253e-03, -1.48909897e-01,  9.62223560e-02,\n",
       "       -1.51839554e-01, -6.07886426e-02,  1.33799344e-01, -2.86759669e-03,\n",
       "       -3.94205488e-02,  1.08268701e-01,  1.75093442e-01,  8.73326585e-02,\n",
       "        2.03454345e-02,  6.41307756e-02,  6.44650683e-02,  3.62752676e-02,\n",
       "        2.80749928e-02,  6.08332716e-02, -1.41322106e-01, -5.42373881e-02,\n",
       "        3.11239865e-02,  6.70062080e-02,  3.14473920e-02, -3.69250849e-02,\n",
       "        8.12530443e-02, -7.48593658e-02, -1.37869954e-01,  7.29414225e-02,\n",
       "       -3.56758945e-02, -1.26365706e-01,  2.08055377e-02,  4.05692160e-02,\n",
       "       -1.14855587e-01,  1.02730207e-01,  3.79777029e-02, -1.41508788e-01,\n",
       "        4.86834496e-02,  1.68592352e-02,  9.11621898e-02,  1.77541338e-02,\n",
       "        6.37671575e-02, -4.42850590e-03,  1.58361718e-02, -3.17489244e-02,\n",
       "       -2.34384444e-02, -1.37510747e-02, -2.36771908e-02, -1.52928770e-01,\n",
       "        2.07747370e-01,  1.09886795e-01, -7.04588648e-03,  2.24905424e-02,\n",
       "        4.40983735e-02,  5.03668599e-02,  6.32670522e-02,  2.09767088e-01,\n",
       "       -1.64108902e-01,  6.66274205e-02,  1.00731909e-01,  3.36627215e-02,\n",
       "        3.05652797e-01, -1.93285793e-01,  1.08418316e-01,  1.00328133e-01,\n",
       "        1.59479063e-02,  1.01006709e-01,  9.98087749e-02,  1.02411352e-01,\n",
       "        9.73610580e-02, -3.09738293e-02, -1.10746980e-01, -3.40849794e-02,\n",
       "        7.26562738e-02,  8.98316056e-02,  9.96894464e-02, -2.12528538e-02,\n",
       "        1.57857880e-01, -4.58718799e-02, -1.23450663e-02, -1.04330629e-02,\n",
       "       -1.14002347e-01, -2.00490952e-01, -6.65412098e-02, -9.14770216e-02,\n",
       "       -9.97638237e-03,  1.08907506e-01, -1.33710071e-01, -3.07493769e-02,\n",
       "       -3.88280526e-02,  5.84756657e-02, -8.24784338e-02, -6.55660927e-02,\n",
       "       -8.13046768e-02,  1.20535657e-01, -1.92590803e-03,  1.38711846e-02,\n",
       "        1.45290226e-01, -3.80027182e-02, -1.32550806e-01,  6.52144775e-02,\n",
       "        7.02840239e-02,  3.97638083e-02,  1.33326292e-01, -6.96850568e-02,\n",
       "        5.59042618e-02,  5.60256541e-02,  7.73168802e-02,  3.93414572e-02,\n",
       "       -1.46324962e-01,  5.37212901e-02,  1.34790659e-01,  6.60873484e-03,\n",
       "       -8.84153545e-02,  1.77761167e-02,  1.61534455e-02,  2.07538586e-02,\n",
       "        3.85472476e-02,  3.48741189e-02, -3.29747051e-02, -1.08351260e-01,\n",
       "        1.12404376e-02,  1.11551389e-01,  3.50611284e-02,  5.61117753e-02,\n",
       "        2.03135848e-01, -4.44126353e-02,  7.68411905e-02, -1.06145315e-01,\n",
       "        1.06344782e-01, -1.52121708e-02,  7.52784405e-03,  9.30526555e-02,\n",
       "       -2.15492934e-01,  1.29548728e-01, -5.78466356e-02, -7.28919208e-02,\n",
       "       -4.96295467e-02,  3.02497353e-02, -2.58389823e-02,  5.16092777e-02,\n",
       "       -8.30971524e-02,  1.26526490e-01,  1.14059553e-01,  6.29279837e-02,\n",
       "       -3.90186831e-02, -5.15357684e-03, -1.00824676e-01, -3.69947068e-02,\n",
       "        1.32129669e-01,  1.92490578e-01, -4.18132059e-02, -3.16301994e-02],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft.get_word_vector('печь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1753038 ,  0.00724031, -0.13455375, -0.00027802,  0.01874303,\n",
       "       -0.01056537,  0.05781734,  0.00851268, -0.12040708, -0.16586418,\n",
       "       -0.10949906,  0.08429632, -0.03035829, -0.1301005 , -0.1000965 ,\n",
       "        0.02976374, -0.10448169,  0.14156461,  0.01680489,  0.07560266,\n",
       "       -0.01589312, -0.09254004,  0.03390333,  0.01686832,  0.06942455,\n",
       "       -0.05103813, -0.13111839, -0.14413178,  0.0188932 ,  0.12781055,\n",
       "       -0.00654911, -0.04281282,  0.0656225 ,  0.05542463,  0.0549427 ,\n",
       "        0.08931478,  0.06213765, -0.09079059, -0.03287039,  0.0982732 ,\n",
       "        0.07428933, -0.11164604,  0.05210447,  0.01079965, -0.05714549,\n",
       "        0.06393512,  0.15666708,  0.01019257,  0.14045039,  0.00819319,\n",
       "        0.05840708, -0.00672886,  0.06866424,  0.00952169,  0.01235682,\n",
       "        0.03092333, -0.00548269,  0.0124651 , -0.04128526,  0.04060575,\n",
       "        0.02289767, -0.08650371, -0.09751538, -0.00596499, -0.025728  ,\n",
       "       -0.01933727, -0.05493296,  0.07499436,  0.05560207, -0.07344314,\n",
       "       -0.03451649, -0.09891073, -0.0208654 ,  0.08895411,  0.04495291,\n",
       "        0.09843836,  0.18265891,  0.00145832,  0.05374351,  0.03829114,\n",
       "        0.05497846, -0.05839469, -0.03451044, -0.01687501, -0.12549087,\n",
       "       -0.02196934, -0.14685372, -0.00284381, -0.0386001 ,  0.01062314,\n",
       "       -0.03922105,  0.09983618, -0.01168197,  0.24557585,  0.07243209,\n",
       "        0.01982304,  0.04688154, -0.0029147 ,  0.08530684, -0.00055054,\n",
       "       -0.06937884, -0.02904436,  0.03496699, -0.06826806, -0.025842  ,\n",
       "       -0.04370945,  0.05380785,  0.06620669, -0.10171285,  0.0440781 ,\n",
       "       -0.08581913,  0.10384911,  0.08209446,  0.04666783, -0.00601356,\n",
       "       -0.06259276, -0.15260673,  0.05689818, -0.03501386,  0.06084138,\n",
       "        0.00722439, -0.03614442, -0.12597774,  0.02034653,  0.00122021,\n",
       "        0.0207154 ,  0.01690587,  0.11414496,  0.01439853,  0.09065063,\n",
       "       -0.11151689, -0.04455929, -0.10098326,  0.13658646, -0.03551207,\n",
       "        0.01824715, -0.00044384,  0.03393303,  0.06357525, -0.00317353,\n",
       "        0.02719299, -0.01984505,  0.05666997, -0.00248334,  0.0306569 ,\n",
       "       -0.09475507,  0.02248129,  0.00714194, -0.01598199,  0.00580228,\n",
       "       -0.0763938 ,  0.01467413, -0.1662802 , -0.02585219,  0.10430494,\n",
       "        0.00168241, -0.01865568,  0.18015042,  0.15752742,  0.04417547,\n",
       "       -0.00715038, -0.07362531, -0.04428612,  0.24052843,  0.04288836,\n",
       "        0.10067508, -0.10239141,  0.01419593,  0.01907814,  0.00319387,\n",
       "       -0.01107803,  0.02898096,  0.02284534,  0.076735  , -0.13409014,\n",
       "        0.00556948,  0.01719637,  0.08783507,  0.010376  , -0.01107714,\n",
       "       -0.10515305,  0.18604112,  0.02168249, -0.03655753,  0.02066791,\n",
       "        0.04377361, -0.03467993,  0.05405822, -0.12236399, -0.01507289,\n",
       "        0.10149784, -0.06270269,  0.0638085 ,  0.03407302, -0.08613651,\n",
       "       -0.13172266, -0.21772218,  0.08621225,  0.10024823,  0.04038155,\n",
       "        0.06306551,  0.13569269,  0.05450044,  0.19322135, -0.07206577,\n",
       "        0.07816121,  0.06338875,  0.02533202,  0.23168935, -0.10102212,\n",
       "        0.05360975,  0.05174841,  0.01548957,  0.08700304,  0.04261158,\n",
       "       -0.00213251,  0.11231004,  0.166601  , -0.01966474, -0.04863847,\n",
       "       -0.02255205,  0.07610025,  0.09902584,  0.04537105,  0.03556815,\n",
       "       -0.06766803,  0.06835531, -0.06212994, -0.06804697, -0.18239963,\n",
       "       -0.08586532,  0.08334012, -0.02382745,  0.02263893, -0.06990163,\n",
       "       -0.05494336,  0.00416031, -0.02160409, -0.03067006, -0.02594637,\n",
       "       -0.00627244, -0.1475677 , -0.00521326, -0.01725447,  0.10696121,\n",
       "        0.00944517, -0.07250708,  0.03586861,  0.04500589,  0.06540069,\n",
       "        0.16014697, -0.09206632, -0.04067697,  0.04263983,  0.17735365,\n",
       "        0.09989069,  0.10434088, -0.0373957 ,  0.0645018 ,  0.03562368,\n",
       "        0.01325474, -0.02608931,  0.03384911, -0.04699459, -0.04524435,\n",
       "        0.0254124 ,  0.00779021, -0.05131128,  0.04397104,  0.10170279,\n",
       "        0.06232408,  0.11507858,  0.21277533,  0.05131346,  0.03267457,\n",
       "       -0.15556598,  0.16414958, -0.00678622, -0.07666589, -0.03451581,\n",
       "       -0.15393835,  0.11078048, -0.01218206, -0.02772524, -0.07143184,\n",
       "        0.02113725, -0.09798808,  0.05468865,  0.13823235,  0.06990397,\n",
       "        0.12634973,  0.01667532, -0.01893351, -0.02236254, -0.0824527 ,\n",
       "       -0.04739464,  0.08540428,  0.12422758, -0.03678842, -0.06826332],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft.get_word_vector('печью')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7612155675888062, 'печкой'),\n",
       " (0.7319516539573669, 'печи'),\n",
       " (0.7223564982414246, 'электропечью'),\n",
       " (0.715794026851654, 'каменкой'),\n",
       " (0.693145751953125, 'печами'),\n",
       " (0.6750300526618958, 'лежанкой'),\n",
       " (0.6694084405899048, 'плитой'),\n",
       " (0.6690734028816223, 'топкой'),\n",
       " (0.6670330762863159, 'буржуйкой'),\n",
       " (0.6548987627029419, 'парилкой')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('печью')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe\n",
    "\n",
    "Предобученную модель GloVe можно взять из той же библиотеки gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove_eng = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47685 , -0.084552,  1.4641  ,  0.047017,  0.14686 ,  0.5082  ,\n",
       "       -1.2228  , -0.22607 ,  0.19306 , -0.29756 ,  0.20599 , -0.71284 ,\n",
       "       -1.6288  ,  0.17096 ,  0.74797 , -0.061943, -0.65766 ,  1.3786  ,\n",
       "       -0.68043 , -1.7551  ,  0.58319 ,  0.25157 , -1.2114  ,  0.81343 ,\n",
       "        0.094825, -1.6819  , -0.64498 ,  0.6322  ,  1.1211  ,  0.16112 ,\n",
       "        2.5379  ,  0.24852 , -0.26816 ,  0.32818 ,  1.2916  ,  0.23548 ,\n",
       "        0.61465 , -0.1344  , -0.13237 ,  0.27398 , -0.11821 ,  0.1354  ,\n",
       "        0.074306, -0.61951 ,  0.45472 , -0.30318 , -0.21883 , -0.56054 ,\n",
       "        1.1177  , -0.36595 ], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_eng['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('truck', 0.92085862159729),\n",
       " ('cars', 0.8870189785957336),\n",
       " ('vehicle', 0.8833683729171753),\n",
       " ('driver', 0.8464019298553467),\n",
       " ('driving', 0.8384189009666443),\n",
       " ('bus', 0.8210511803627014),\n",
       " ('vehicles', 0.8174992799758911),\n",
       " ('parked', 0.7902189493179321),\n",
       " ('motorcycle', 0.7866503000259399),\n",
       " ('taxi', 0.7833929657936096)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_eng.most_similar(['car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные ссылки на предобученные модели\n",
    "\n",
    "1. [Библиотека Gensim](https://radimrehurek.com/gensim/index.html).\n",
    "2. [Word2Vec в Gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n",
    "3. [Библиотека fastText](https://fasttext.cc/).\n",
    "4. [Предварительно обученные векторные представления для 157 языков](https://fasttext.cc/docs/en/crawl-vectors.html).\n",
    "3. [Библиотека navec](https://natasha.github.io/navec/).\n",
    "4. [Navec — компактные эмбеддинги для русского языка](https://natasha.github.io/navec/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение Word2Vec на своих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "url = 'https://www.dropbox.com/s/a9r0b2yj3vqvi13/banks.csv?dl=1'\n",
    "filename = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = pd.read_csv(filename, sep='\\t', index_col='idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>Positive</td>\n",
       "      <td>О высокой надёжности МКБ, порядочности и добро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Обслуживаюсь в офисе на Чернореченской 42а, ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Попала сегодня в очень неприятную ситуацию. Ре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Добрый день! Давно являюсь клиентом банка Русс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Сначала было все банально. Взял в кредит mp3 п...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score                                               Text\n",
       "idx                                                               \n",
       "0      Positive  В Альфа-Банке работает замечательная девушка -...\n",
       "1      Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...\n",
       "2      Positive  Очень порадовала оперативность работы в банке....\n",
       "3      Negative  Имела неосторожность оформить потреб. кредит в...\n",
       "4      Negative  Небольшая предыстория: Нашел на сайте MDM банк...\n",
       "...         ...                                                ...\n",
       "13994  Positive  О высокой надёжности МКБ, порядочности и добро...\n",
       "13995  Positive  Обслуживаюсь в офисе на Чернореченской 42а, ка...\n",
       "13996  Positive  Попала сегодня в очень неприятную ситуацию. Ре...\n",
       "13997  Positive  Добрый день! Давно являюсь клиентом банка Русс...\n",
       "13998  Negative  Сначала было все банально. Взял в кредит mp3 п...\n",
       "\n",
       "[13999 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks['Preprocessed_texts'] = banks.apply(lambda row: preprocess(row['Text'], stops_words_ru), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "      <td>[работает, замечательная, девушка, ильясова, о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "      <td>[оформляя, рассрочку, видео, меге, тёплый, ста...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "      <td>[очень, порадовала, оперативность, работы, бан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "      <td>[имела, неосторожность, оформить, потреб, кред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "      <td>[небольшая, предыстория, нашел, сайте, mdm, ба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>Positive</td>\n",
       "      <td>О высокой надёжности МКБ, порядочности и добро...</td>\n",
       "      <td>[высокой, надёжности, мкб, порядочности, добро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Обслуживаюсь в офисе на Чернореченской 42а, ка...</td>\n",
       "      <td>[обслуживаюсь, офисе, чернореченской, физ, лиц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Попала сегодня в очень неприятную ситуацию. Ре...</td>\n",
       "      <td>[попала, сегодня, очень, неприятную, ситуацию,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Добрый день! Давно являюсь клиентом банка Русс...</td>\n",
       "      <td>[добрый, день, давно, являюсь, клиентом, банка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Сначала было все банально. Взял в кредит mp3 п...</td>\n",
       "      <td>[сначала, банально, взял, кредит, плеер, мес, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score                                               Text  \\\n",
       "idx                                                                  \n",
       "0      Positive  В Альфа-Банке работает замечательная девушка -...   \n",
       "1      Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...   \n",
       "2      Positive  Очень порадовала оперативность работы в банке....   \n",
       "3      Negative  Имела неосторожность оформить потреб. кредит в...   \n",
       "4      Negative  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
       "...         ...                                                ...   \n",
       "13994  Positive  О высокой надёжности МКБ, порядочности и добро...   \n",
       "13995  Positive  Обслуживаюсь в офисе на Чернореченской 42а, ка...   \n",
       "13996  Positive  Попала сегодня в очень неприятную ситуацию. Ре...   \n",
       "13997  Positive  Добрый день! Давно являюсь клиентом банка Русс...   \n",
       "13998  Negative  Сначала было все банально. Взял в кредит mp3 п...   \n",
       "\n",
       "                                      Preprocessed_texts  \n",
       "idx                                                       \n",
       "0      [работает, замечательная, девушка, ильясова, о...  \n",
       "1      [оформляя, рассрочку, видео, меге, тёплый, ста...  \n",
       "2      [очень, порадовала, оперативность, работы, бан...  \n",
       "3      [имела, неосторожность, оформить, потреб, кред...  \n",
       "4      [небольшая, предыстория, нашел, сайте, mdm, ба...  \n",
       "...                                                  ...  \n",
       "13994  [высокой, надёжности, мкб, порядочности, добро...  \n",
       "13995  [обслуживаюсь, офисе, чернореченской, физ, лиц...  \n",
       "13996  [попала, сегодня, очень, неприятную, ситуацию,...  \n",
       "13997  [добрый, день, давно, являюсь, клиентом, банка...  \n",
       "13998  [сначала, банально, взял, кредит, плеер, мес, ...  \n",
       "\n",
       "[13999 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=banks['Preprocessed_texts'],\n",
    "                               min_count=5,\n",
    "                               vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08531082, -0.41040078, -1.2961476 , -0.6656613 ,  0.13305381,\n",
       "        0.05057921,  0.82577777,  1.2180654 , -0.91023386,  0.10134134,\n",
       "       -0.33615366, -0.27407005, -0.6530234 , -1.4890761 , -0.8337082 ,\n",
       "        0.57433915,  0.6194244 , -0.8240212 ,  0.12153419, -0.69451576,\n",
       "       -0.17902806,  1.0278157 ,  0.6737105 ,  0.23140655,  0.54348725,\n",
       "       -1.9284692 ,  1.2045925 , -1.1909448 ,  0.21313716, -1.1008369 ,\n",
       "        0.4908453 , -0.36450425,  0.2702667 ,  0.50219333, -0.6121471 ,\n",
       "        0.78456193,  0.5670301 , -1.387147  , -0.46688375,  0.7368093 ,\n",
       "        0.8076721 , -1.2398353 , -0.54702705,  0.94673264,  0.2986714 ,\n",
       "        1.127015  , -0.40733224,  0.5913734 , -0.14767535,  0.6048299 ,\n",
       "        0.7165103 , -1.798116  ,  0.49813175,  0.97189826, -1.8800792 ,\n",
       "        0.20650798,  1.0045443 ,  0.48688737, -1.3046933 ,  0.3960795 ,\n",
       "        0.10540345,  0.80151385, -0.2935625 , -1.937169  ,  0.206786  ,\n",
       "       -1.0573828 ,  1.4519833 ,  1.8616426 ,  0.43912435, -0.5589914 ,\n",
       "        0.9846969 , -0.15931723,  0.6797283 ,  0.7200648 , -0.02855407,\n",
       "       -0.35635138, -0.5935209 ,  0.70254195, -1.1229657 ,  0.84113467,\n",
       "        0.01458869, -0.39529982, -1.0627779 ,  0.53125644, -1.4631231 ,\n",
       "       -0.3097215 , -1.1046008 ,  0.62295157,  0.12848596, -0.41626638,\n",
       "       -0.15204066, -1.4812691 ,  0.9237642 ,  0.1468254 , -0.3209756 ,\n",
       "        1.0246897 ,  0.38628188, -1.3529158 ,  0.7785711 , -0.38759878],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['работать']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14243744, -0.09188487,  0.06645581, -0.1370332 , -0.23854269,\n",
       "       -0.27082646, -0.17151079,  0.483381  , -0.63861114,  0.12301378,\n",
       "        0.13728085, -0.04301038,  0.30721578,  0.124957  ,  0.29704887,\n",
       "       -0.13535517,  0.3045485 , -0.43771914, -0.0235233 , -0.48804736,\n",
       "        0.17106162,  0.18449074,  0.2955115 , -0.16800134,  0.07400453,\n",
       "        0.10816153, -0.11680923, -0.03580258, -0.4706628 , -0.10558249,\n",
       "        0.3104722 , -0.2283011 ,  0.24349596, -0.30175582, -0.35549217,\n",
       "        0.27378955, -0.01867673, -0.25607845,  0.1328438 , -0.2965627 ,\n",
       "        0.13483457, -0.42717505, -0.48364583, -0.0091152 ,  0.2629256 ,\n",
       "        0.08242698, -0.19713436, -0.0475959 , -0.08383262,  0.4330561 ,\n",
       "       -0.1056499 , -0.52020514, -0.08197866,  0.00891048, -0.15326926,\n",
       "        0.4785084 ,  0.3874909 , -0.19257371, -0.3508786 ,  0.29572162,\n",
       "       -0.21896039,  0.06516223, -0.3863423 , -0.01128248,  0.13218783,\n",
       "       -0.07674706,  0.05120785,  0.325392  , -0.2561403 , -0.13521206,\n",
       "        0.21603099,  0.46140844,  0.17357807, -0.01477713,  0.23842636,\n",
       "        0.28613243, -0.2909185 , -0.05478327, -0.28551382,  0.11822525,\n",
       "       -0.13818829, -0.10885153,  0.03918646,  0.36522642, -0.01490581,\n",
       "        0.07506149, -0.18194176,  0.1854187 , -0.16427793,  0.06751946,\n",
       "        0.2440007 ,  0.02070433,  0.3658217 ,  0.22200139,  0.2371152 ,\n",
       "        0.653855  ,  0.1606686 , -0.4899456 ,  0.2631303 , -0.32979822],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['замечательный']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('современный', 0.9023762345314026),\n",
       " ('крупный', 0.8954980969429016),\n",
       " ('известный', 0.8729244470596313),\n",
       " ('надежный', 0.8666946887969971),\n",
       " ('достойный', 0.8656669855117798),\n",
       " ('великолепный', 0.8606410026550293),\n",
       " ('попался', 0.8525636792182922),\n",
       " ('адекватный', 0.8440741300582886),\n",
       " ('позитивный', 0.843691349029541),\n",
       " ('рядовой', 0.842851996421814)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('замечательный')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('word2vec-banki.ru-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка сохраненной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = gensim.models.Word2Vec.load('word2vec-banki.ru-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08531082, -0.41040078, -1.2961476 , -0.6656613 ,  0.13305381,\n",
       "        0.05057921,  0.82577777,  1.2180654 , -0.91023386,  0.10134134,\n",
       "       -0.33615366, -0.27407005, -0.6530234 , -1.4890761 , -0.8337082 ,\n",
       "        0.57433915,  0.6194244 , -0.8240212 ,  0.12153419, -0.69451576,\n",
       "       -0.17902806,  1.0278157 ,  0.6737105 ,  0.23140655,  0.54348725,\n",
       "       -1.9284692 ,  1.2045925 , -1.1909448 ,  0.21313716, -1.1008369 ,\n",
       "        0.4908453 , -0.36450425,  0.2702667 ,  0.50219333, -0.6121471 ,\n",
       "        0.78456193,  0.5670301 , -1.387147  , -0.46688375,  0.7368093 ,\n",
       "        0.8076721 , -1.2398353 , -0.54702705,  0.94673264,  0.2986714 ,\n",
       "        1.127015  , -0.40733224,  0.5913734 , -0.14767535,  0.6048299 ,\n",
       "        0.7165103 , -1.798116  ,  0.49813175,  0.97189826, -1.8800792 ,\n",
       "        0.20650798,  1.0045443 ,  0.48688737, -1.3046933 ,  0.3960795 ,\n",
       "        0.10540345,  0.80151385, -0.2935625 , -1.937169  ,  0.206786  ,\n",
       "       -1.0573828 ,  1.4519833 ,  1.8616426 ,  0.43912435, -0.5589914 ,\n",
       "        0.9846969 , -0.15931723,  0.6797283 ,  0.7200648 , -0.02855407,\n",
       "       -0.35635138, -0.5935209 ,  0.70254195, -1.1229657 ,  0.84113467,\n",
       "        0.01458869, -0.39529982, -1.0627779 ,  0.53125644, -1.4631231 ,\n",
       "       -0.3097215 , -1.1046008 ,  0.62295157,  0.12848596, -0.41626638,\n",
       "       -0.15204066, -1.4812691 ,  0.9237642 ,  0.1468254 , -0.3209756 ,\n",
       "        1.0246897 ,  0.38628188, -1.3529158 ,  0.7785711 , -0.38759878],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.wv['работать']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение тональности текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_words = 10000\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "      <td>[работает, замечательная, девушка, ильясова, о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "      <td>[оформляя, рассрочку, видео, меге, тёплый, ста...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "      <td>[очень, порадовала, оперативность, работы, бан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "      <td>[имела, неосторожность, оформить, потреб, кред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "      <td>[небольшая, предыстория, нашел, сайте, mdm, ба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>Positive</td>\n",
       "      <td>О высокой надёжности МКБ, порядочности и добро...</td>\n",
       "      <td>[высокой, надёжности, мкб, порядочности, добро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Обслуживаюсь в офисе на Чернореченской 42а, ка...</td>\n",
       "      <td>[обслуживаюсь, офисе, чернореченской, физ, лиц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Попала сегодня в очень неприятную ситуацию. Ре...</td>\n",
       "      <td>[попала, сегодня, очень, неприятную, ситуацию,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Добрый день! Давно являюсь клиентом банка Русс...</td>\n",
       "      <td>[добрый, день, давно, являюсь, клиентом, банка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Сначала было все банально. Взял в кредит mp3 п...</td>\n",
       "      <td>[сначала, банально, взял, кредит, плеер, мес, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score                                               Text  \\\n",
       "idx                                                                  \n",
       "0      Positive  В Альфа-Банке работает замечательная девушка -...   \n",
       "1      Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...   \n",
       "2      Positive  Очень порадовала оперативность работы в банке....   \n",
       "3      Negative  Имела неосторожность оформить потреб. кредит в...   \n",
       "4      Negative  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
       "...         ...                                                ...   \n",
       "13994  Positive  О высокой надёжности МКБ, порядочности и добро...   \n",
       "13995  Positive  Обслуживаюсь в офисе на Чернореченской 42а, ка...   \n",
       "13996  Positive  Попала сегодня в очень неприятную ситуацию. Ре...   \n",
       "13997  Positive  Добрый день! Давно являюсь клиентом банка Русс...   \n",
       "13998  Negative  Сначала было все банально. Взял в кредит mp3 п...   \n",
       "\n",
       "                                      Preprocessed_texts  \n",
       "idx                                                       \n",
       "0      [работает, замечательная, девушка, ильясова, о...  \n",
       "1      [оформляя, рассрочку, видео, меге, тёплый, ста...  \n",
       "2      [очень, порадовала, оперативность, работы, бан...  \n",
       "3      [имела, неосторожность, оформить, потреб, кред...  \n",
       "4      [небольшая, предыстория, нашел, сайте, mdm, ба...  \n",
       "...                                                  ...  \n",
       "13994  [высокой, надёжности, мкб, порядочности, добро...  \n",
       "13995  [обслуживаюсь, офисе, чернореченской, физ, лиц...  \n",
       "13996  [попала, сегодня, очень, неприятную, ситуацию,...  \n",
       "13997  [добрый, день, давно, являюсь, клиентом, банка...  \n",
       "13998  [сначала, банально, взял, кредит, плеер, мес, ...  \n",
       "\n",
       "[13999 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем частоту слов во всех отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in banks['Preprocessed_texts']:\n",
    "    words.update(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь, упорядоченный по частоте\n",
    "\n",
    "В словаре будем использовать 2 специальных кода:\n",
    "- Код заполнитель: 0\n",
    "- Неизвестное слово: 1\n",
    "\n",
    "Нумерация слов в словаре начинается с 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь, отображающий слова в коды\n",
    "word_to_index = dict()\n",
    "# Словарь, отображающий коды в слова\n",
    "index_to_word = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словари"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(words.most_common(max_words - 2)):\n",
    "    word_to_index[word[0]] = i + 2\n",
    "    index_to_word[i + 2] = word[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для преобразования списка слов в список кодов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(txt, word_to_index):\n",
    "    seq = []\n",
    "    for word in txt:\n",
    "        index = word_to_index.get(word, 1) # 1 означает неизвестное слово\n",
    "        # Неизвестные слова не добавляем в выходную последовательность\n",
    "        if index != 1:\n",
    "            seq.append(index)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем все тексты в последовательность кодов слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks['Sequences'] = banks.apply(lambda row: text_to_sequence(row['Preprocessed_texts'], word_to_index), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "      <th>Sequences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "      <td>[работает, замечательная, девушка, ильясова, о...</td>\n",
       "      <td>[113, 7310, 57, 3119, 226, 7612, 117, 3564, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "      <td>[оформляя, рассрочку, видео, меге, тёплый, ста...</td>\n",
       "      <td>[7796, 1359, 4406, 454, 542, 543, 371, 85, 352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "      <td>[очень, порадовала, оперативность, работы, бан...</td>\n",
       "      <td>[7, 4525, 1090, 92, 12, 1472, 152, 6, 499, 195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "      <td>[имела, неосторожность, оформить, потреб, кред...</td>\n",
       "      <td>[2286, 7797, 194, 3566, 9, 7, 4051, 6, 494, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "      <td>[небольшая, предыстория, нашел, сайте, mdm, ба...</td>\n",
       "      <td>[1767, 7150, 1235, 72, 2, 6, 7798, 3, 858, 78,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>Positive</td>\n",
       "      <td>О высокой надёжности МКБ, порядочности и добро...</td>\n",
       "      <td>[высокой, надёжности, мкб, порядочности, добро...</td>\n",
       "      <td>[3671, 706, 48, 4192, 349, 4608, 413, 24, 918,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Обслуживаюсь в офисе на Чернореченской 42а, ка...</td>\n",
       "      <td>[обслуживаюсь, офисе, чернореченской, физ, лиц...</td>\n",
       "      <td>[876, 106, 2529, 864, 116, 106, 669, 968, 98, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Попала сегодня в очень неприятную ситуацию. Ре...</td>\n",
       "      <td>[попала, сегодня, очень, неприятную, ситуацию,...</td>\n",
       "      <td>[2204, 47, 7, 8156, 188, 279, 372, 403, 50, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Добрый день! Давно являюсь клиентом банка Русс...</td>\n",
       "      <td>[добрый, день, давно, являюсь, клиентом, банка...</td>\n",
       "      <td>[148, 10, 271, 99, 53, 2, 1027, 1007, 421, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Сначала было все банально. Взял в кредит mp3 п...</td>\n",
       "      <td>[сначала, банально, взял, кредит, плеер, мес, ...</td>\n",
       "      <td>[323, 6163, 476, 9, 2334, 1604, 549, 9552, 721...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score                                               Text  \\\n",
       "idx                                                                  \n",
       "0      Positive  В Альфа-Банке работает замечательная девушка -...   \n",
       "1      Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...   \n",
       "2      Positive  Очень порадовала оперативность работы в банке....   \n",
       "3      Negative  Имела неосторожность оформить потреб. кредит в...   \n",
       "4      Negative  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
       "...         ...                                                ...   \n",
       "13994  Positive  О высокой надёжности МКБ, порядочности и добро...   \n",
       "13995  Positive  Обслуживаюсь в офисе на Чернореченской 42а, ка...   \n",
       "13996  Positive  Попала сегодня в очень неприятную ситуацию. Ре...   \n",
       "13997  Positive  Добрый день! Давно являюсь клиентом банка Русс...   \n",
       "13998  Negative  Сначала было все банально. Взял в кредит mp3 п...   \n",
       "\n",
       "                                      Preprocessed_texts  \\\n",
       "idx                                                        \n",
       "0      [работает, замечательная, девушка, ильясова, о...   \n",
       "1      [оформляя, рассрочку, видео, меге, тёплый, ста...   \n",
       "2      [очень, порадовала, оперативность, работы, бан...   \n",
       "3      [имела, неосторожность, оформить, потреб, кред...   \n",
       "4      [небольшая, предыстория, нашел, сайте, mdm, ба...   \n",
       "...                                                  ...   \n",
       "13994  [высокой, надёжности, мкб, порядочности, добро...   \n",
       "13995  [обслуживаюсь, офисе, чернореченской, физ, лиц...   \n",
       "13996  [попала, сегодня, очень, неприятную, ситуацию,...   \n",
       "13997  [добрый, день, давно, являюсь, клиентом, банка...   \n",
       "13998  [сначала, банально, взял, кредит, плеер, мес, ...   \n",
       "\n",
       "                                               Sequences  \n",
       "idx                                                       \n",
       "0      [113, 7310, 57, 3119, 226, 7612, 117, 3564, 29...  \n",
       "1      [7796, 1359, 4406, 454, 542, 543, 371, 85, 352...  \n",
       "2      [7, 4525, 1090, 92, 12, 1472, 152, 6, 499, 195...  \n",
       "3      [2286, 7797, 194, 3566, 9, 7, 4051, 6, 494, 30...  \n",
       "4      [1767, 7150, 1235, 72, 2, 6, 7798, 3, 858, 78,...  \n",
       "...                                                  ...  \n",
       "13994  [3671, 706, 48, 4192, 349, 4608, 413, 24, 918,...  \n",
       "13995  [876, 106, 2529, 864, 116, 106, 669, 968, 98, ...  \n",
       "13996  [2204, 47, 7, 8156, 188, 279, 372, 403, 50, 16...  \n",
       "13997  [148, 10, 271, 99, 53, 2, 1027, 1007, 421, 197...  \n",
       "13998  [323, 6163, 476, 9, 2334, 1604, 549, 9552, 721...  \n",
       "\n",
       "[13999 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим данные для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текстовые метки классов в числовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Negative': 0, 'Positive': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks.replace({'Score': mapping}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "      <th>Sequences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "      <td>[работает, замечательная, девушка, ильясова, о...</td>\n",
       "      <td>[113, 7310, 57, 3119, 226, 7612, 117, 3564, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "      <td>[оформляя, рассрочку, видео, меге, тёплый, ста...</td>\n",
       "      <td>[7796, 1359, 4406, 454, 542, 543, 371, 85, 352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "      <td>[очень, порадовала, оперативность, работы, бан...</td>\n",
       "      <td>[7, 4525, 1090, 92, 12, 1472, 152, 6, 499, 195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "      <td>[имела, неосторожность, оформить, потреб, кред...</td>\n",
       "      <td>[2286, 7797, 194, 3566, 9, 7, 4051, 6, 494, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "      <td>[небольшая, предыстория, нашел, сайте, mdm, ба...</td>\n",
       "      <td>[1767, 7150, 1235, 72, 2, 6, 7798, 3, 858, 78,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>1</td>\n",
       "      <td>О высокой надёжности МКБ, порядочности и добро...</td>\n",
       "      <td>[высокой, надёжности, мкб, порядочности, добро...</td>\n",
       "      <td>[3671, 706, 48, 4192, 349, 4608, 413, 24, 918,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1</td>\n",
       "      <td>Обслуживаюсь в офисе на Чернореченской 42а, ка...</td>\n",
       "      <td>[обслуживаюсь, офисе, чернореченской, физ, лиц...</td>\n",
       "      <td>[876, 106, 2529, 864, 116, 106, 669, 968, 98, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>1</td>\n",
       "      <td>Попала сегодня в очень неприятную ситуацию. Ре...</td>\n",
       "      <td>[попала, сегодня, очень, неприятную, ситуацию,...</td>\n",
       "      <td>[2204, 47, 7, 8156, 188, 279, 372, 403, 50, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>1</td>\n",
       "      <td>Добрый день! Давно являюсь клиентом банка Русс...</td>\n",
       "      <td>[добрый, день, давно, являюсь, клиентом, банка...</td>\n",
       "      <td>[148, 10, 271, 99, 53, 2, 1027, 1007, 421, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>0</td>\n",
       "      <td>Сначала было все банально. Взял в кредит mp3 п...</td>\n",
       "      <td>[сначала, банально, взял, кредит, плеер, мес, ...</td>\n",
       "      <td>[323, 6163, 476, 9, 2334, 1604, 549, 9552, 721...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score                                               Text  \\\n",
       "idx                                                               \n",
       "0          1  В Альфа-Банке работает замечательная девушка -...   \n",
       "1          0  Оформляя рассрочку в м. Видео в меге тёплый ст...   \n",
       "2          1  Очень порадовала оперативность работы в банке....   \n",
       "3          0  Имела неосторожность оформить потреб. кредит в...   \n",
       "4          0  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
       "...      ...                                                ...   \n",
       "13994      1  О высокой надёжности МКБ, порядочности и добро...   \n",
       "13995      1  Обслуживаюсь в офисе на Чернореченской 42а, ка...   \n",
       "13996      1  Попала сегодня в очень неприятную ситуацию. Ре...   \n",
       "13997      1  Добрый день! Давно являюсь клиентом банка Русс...   \n",
       "13998      0  Сначала было все банально. Взял в кредит mp3 п...   \n",
       "\n",
       "                                      Preprocessed_texts  \\\n",
       "idx                                                        \n",
       "0      [работает, замечательная, девушка, ильясова, о...   \n",
       "1      [оформляя, рассрочку, видео, меге, тёплый, ста...   \n",
       "2      [очень, порадовала, оперативность, работы, бан...   \n",
       "3      [имела, неосторожность, оформить, потреб, кред...   \n",
       "4      [небольшая, предыстория, нашел, сайте, mdm, ба...   \n",
       "...                                                  ...   \n",
       "13994  [высокой, надёжности, мкб, порядочности, добро...   \n",
       "13995  [обслуживаюсь, офисе, чернореченской, физ, лиц...   \n",
       "13996  [попала, сегодня, очень, неприятную, ситуацию,...   \n",
       "13997  [добрый, день, давно, являюсь, клиентом, банка...   \n",
       "13998  [сначала, банально, взял, кредит, плеер, мес, ...   \n",
       "\n",
       "                                               Sequences  \n",
       "idx                                                       \n",
       "0      [113, 7310, 57, 3119, 226, 7612, 117, 3564, 29...  \n",
       "1      [7796, 1359, 4406, 454, 542, 543, 371, 85, 352...  \n",
       "2      [7, 4525, 1090, 92, 12, 1472, 152, 6, 499, 195...  \n",
       "3      [2286, 7797, 194, 3566, 9, 7, 4051, 6, 494, 30...  \n",
       "4      [1767, 7150, 1235, 72, 2, 6, 7798, 3, 858, 78,...  \n",
       "...                                                  ...  \n",
       "13994  [3671, 706, 48, 4192, 349, 4608, 413, 24, 918,...  \n",
       "13995  [876, 106, 2529, 864, 116, 106, 669, 968, 98, ...  \n",
       "13996  [2204, 47, 7, 8156, 188, 279, 372, 403, 50, 16...  \n",
       "13997  [148, 10, 271, 99, 53, 2, 1027, 1007, 421, 197...  \n",
       "13998  [323, 6163, 476, 9, 2334, 1604, 549, 9552, 721...  \n",
       "\n",
       "[13999 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделяем данные для обучения и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(banks, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "      <th>Sequences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>0</td>\n",
       "      <td>Всем посетителям Банки.ру добрый день. 05.11.2...</td>\n",
       "      <td>[всем, посетителям, добрый, день, заключил, до...</td>\n",
       "      <td>[95, 9206, 148, 10, 5803, 66, 949, 24, 23, 460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>0</td>\n",
       "      <td>27 января 2017 я снимала деньги с карты Тинько...</td>\n",
       "      <td>[января, снимала, деньги, карты, тинькофф, бан...</td>\n",
       "      <td>[523, 5188, 5, 8, 1489, 2, 649, 1352, 186, 261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>В октябре 2011 года через вирусную программу с...</td>\n",
       "      <td>[октябре, года, вирусную, программу, моего, сч...</td>\n",
       "      <td>[1962, 15, 2149, 79, 21, 332, 506, 3343, 23, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12038</th>\n",
       "      <td>0</td>\n",
       "      <td>В связи с утерей был вынужден перевыпустить ка...</td>\n",
       "      <td>[связи, утерей, вынужден, перевыпустить, карту...</td>\n",
       "      <td>[163, 1503, 1728, 6, 13, 671, 3406, 586, 3802,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>0</td>\n",
       "      <td>ПРЕТЕНЗИЯ08.04.2015 г. в магазине торговой сет...</td>\n",
       "      <td>[магазине, торговой, сети, ооо, расположенного...</td>\n",
       "      <td>[579, 3782, 2221, 724, 5430, 261, 2567, 1635, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>1</td>\n",
       "      <td>Я не сотрудник Альфа-банка, но скажу пару слов...</td>\n",
       "      <td>[сотрудник, скажу, пару, слов, поддержку, тех,...</td>\n",
       "      <td>[35, 965, 207, 815, 1010, 385, 1402, 1487, 428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>1</td>\n",
       "      <td>Хотелось бы поблагодарить за отличную консульт...</td>\n",
       "      <td>[хотелось, поблагодарить, отличную, консультац...</td>\n",
       "      <td>[231, 780, 2913, 1782, 154, 7161, 5279, 7, 178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>1</td>\n",
       "      <td>Доброго времени суток. Сегодня, (а точнее уже ...</td>\n",
       "      <td>[доброго, времени, суток, сегодня, точнее, вче...</td>\n",
       "      <td>[1215, 74, 873, 47, 1609, 394, 621, 1052, 5851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0</td>\n",
       "      <td>Господа вот уже второй раз мне приходится писа...</td>\n",
       "      <td>[господа, второй, приходится, писать, отзыв, в...</td>\n",
       "      <td>[1514, 259, 726, 283, 158, 683, 12, 47, 1108, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>1</td>\n",
       "      <td>Я недавно клиент Райффайзена, обслуживаюсь в о...</td>\n",
       "      <td>[недавно, клиент, райффайзена, обслуживаюсь, о...</td>\n",
       "      <td>[503, 157, 6027, 876, 29, 9006, 5581, 1867, 78...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score                                               Text  \\\n",
       "idx                                                               \n",
       "3363       0  Всем посетителям Банки.ру добрый день. 05.11.2...   \n",
       "4365       0  27 января 2017 я снимала деньги с карты Тинько...   \n",
       "259        1  В октябре 2011 года через вирусную программу с...   \n",
       "12038      0  В связи с утерей был вынужден перевыпустить ка...   \n",
       "3784       0  ПРЕТЕНЗИЯ08.04.2015 г. в магазине торговой сет...   \n",
       "...      ...                                                ...   \n",
       "7797       1  Я не сотрудник Альфа-банка, но скажу пару слов...   \n",
       "6937       1  Хотелось бы поблагодарить за отличную консульт...   \n",
       "5824       1  Доброго времени суток. Сегодня, (а точнее уже ...   \n",
       "4858       0  Господа вот уже второй раз мне приходится писа...   \n",
       "2394       1  Я недавно клиент Райффайзена, обслуживаюсь в о...   \n",
       "\n",
       "                                      Preprocessed_texts  \\\n",
       "idx                                                        \n",
       "3363   [всем, посетителям, добрый, день, заключил, до...   \n",
       "4365   [января, снимала, деньги, карты, тинькофф, бан...   \n",
       "259    [октябре, года, вирусную, программу, моего, сч...   \n",
       "12038  [связи, утерей, вынужден, перевыпустить, карту...   \n",
       "3784   [магазине, торговой, сети, ооо, расположенного...   \n",
       "...                                                  ...   \n",
       "7797   [сотрудник, скажу, пару, слов, поддержку, тех,...   \n",
       "6937   [хотелось, поблагодарить, отличную, консультац...   \n",
       "5824   [доброго, времени, суток, сегодня, точнее, вче...   \n",
       "4858   [господа, второй, приходится, писать, отзыв, в...   \n",
       "2394   [недавно, клиент, райффайзена, обслуживаюсь, о...   \n",
       "\n",
       "                                               Sequences  \n",
       "idx                                                       \n",
       "3363   [95, 9206, 148, 10, 5803, 66, 949, 24, 23, 460...  \n",
       "4365   [523, 5188, 5, 8, 1489, 2, 649, 1352, 186, 261...  \n",
       "259    [1962, 15, 2149, 79, 21, 332, 506, 3343, 23, 1...  \n",
       "12038  [163, 1503, 1728, 6, 13, 671, 3406, 586, 3802,...  \n",
       "3784   [579, 3782, 2221, 724, 5430, 261, 2567, 1635, ...  \n",
       "...                                                  ...  \n",
       "7797   [35, 965, 207, 815, 1010, 385, 1402, 1487, 428...  \n",
       "6937   [231, 780, 2913, 1782, 154, 7161, 5279, 7, 178...  \n",
       "5824   [1215, 74, 873, 47, 1609, 394, 621, 1052, 5851...  \n",
       "4858   [1514, 259, 726, 283, 158, 683, 12, 47, 1108, ...  \n",
       "2394   [503, 157, 6027, 876, 29, 9006, 5581, 1867, 78...  \n",
       "\n",
       "[11199 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_texts</th>\n",
       "      <th>Sequences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7292</th>\n",
       "      <td>0</td>\n",
       "      <td>21 августа получил sms от Банка Альфа-Банк пре...</td>\n",
       "      <td>[августа, получил, sm, банка, предлагает, дебе...</td>\n",
       "      <td>[529, 69, 1138, 2, 1622, 616, 6, 1282, 1184, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0</td>\n",
       "      <td>Являюсь клиентом Альфа банка с 2002 года и ник...</td>\n",
       "      <td>[являюсь, клиентом, альфа, банка, года, возник...</td>\n",
       "      <td>[99, 53, 88, 2, 15, 1536, 97, 2040, 63, 303, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>0</td>\n",
       "      <td>Добрый вечер.Не получили вознаграждение 2500,0...</td>\n",
       "      <td>[добрый, получили, вознаграждение, рублей, кре...</td>\n",
       "      <td>[148, 1080, 8545, 23, 87, 50, 2, 202, 1801, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>29 июня 2015 г. совершил на свою карту Кукуруз...</td>\n",
       "      <td>[июня, совершил, карту, кукуруза, перевода, пр...</td>\n",
       "      <td>[555, 2520, 6, 631, 1618, 8, 776, 2, 559, 417,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>0</td>\n",
       "      <td>Добрый день!Надеюсь кто то из руководства банк...</td>\n",
       "      <td>[добрый, день, надеюсь, руководства, банка, эт...</td>\n",
       "      <td>[148, 10, 246, 1889, 2, 4, 209, 4565, 1592, 83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754</th>\n",
       "      <td>1</td>\n",
       "      <td>По кредитной карточке жены Visa Ситибанка 7 ию...</td>\n",
       "      <td>[кредитной, карточке, жены, visa, ситибанка, и...</td>\n",
       "      <td>[87, 3460, 2063, 499, 2018, 555, 4086, 1189, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>0</td>\n",
       "      <td>Как я понимаю не я один попался на крючок по п...</td>\n",
       "      <td>[понимаю, попался, крючок, поводу, года, зашел...</td>\n",
       "      <td>[289, 7086, 317, 15, 838, 420, 2327, 2503, 615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0</td>\n",
       "      <td>Подавал документы на кредитную карту Visa Clas...</td>\n",
       "      <td>[подавал, документы, кредитную, карту, visa, c...</td>\n",
       "      <td>[2052, 54, 138, 6, 499, 1952, 882, 7695, 1082,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>0</td>\n",
       "      <td>В общем история такая:Публикую переписку 3-хго...</td>\n",
       "      <td>[общем, история, такая, публикую, переписку, д...</td>\n",
       "      <td>[112, 355, 334, 7743, 6466, 531, 9965, 1917, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6535</th>\n",
       "      <td>1</td>\n",
       "      <td>Вчера обратилась в офис Мособлбанка, находящий...</td>\n",
       "      <td>[вчера, обратилась, офис, мособлбанка, находящ...</td>\n",
       "      <td>[394, 340, 33, 4472, 5552, 485, 7411, 1230, 65...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score                                               Text  \\\n",
       "idx                                                              \n",
       "7292      0  21 августа получил sms от Банка Альфа-Банк пре...   \n",
       "342       0  Являюсь клиентом Альфа банка с 2002 года и ник...   \n",
       "2216      0  Добрый вечер.Не получили вознаграждение 2500,0...   \n",
       "2606      0  29 июня 2015 г. совершил на свою карту Кукуруз...   \n",
       "6572      0  Добрый день!Надеюсь кто то из руководства банк...   \n",
       "...     ...                                                ...   \n",
       "7754      1  По кредитной карточке жены Visa Ситибанка 7 ию...   \n",
       "7023      0  Как я понимаю не я один попался на крючок по п...   \n",
       "668       0  Подавал документы на кредитную карту Visa Clas...   \n",
       "5174      0  В общем история такая:Публикую переписку 3-хго...   \n",
       "6535      1  Вчера обратилась в офис Мособлбанка, находящий...   \n",
       "\n",
       "                                     Preprocessed_texts  \\\n",
       "idx                                                       \n",
       "7292  [августа, получил, sm, банка, предлагает, дебе...   \n",
       "342   [являюсь, клиентом, альфа, банка, года, возник...   \n",
       "2216  [добрый, получили, вознаграждение, рублей, кре...   \n",
       "2606  [июня, совершил, карту, кукуруза, перевода, пр...   \n",
       "6572  [добрый, день, надеюсь, руководства, банка, эт...   \n",
       "...                                                 ...   \n",
       "7754  [кредитной, карточке, жены, visa, ситибанка, и...   \n",
       "7023  [понимаю, попался, крючок, поводу, года, зашел...   \n",
       "668   [подавал, документы, кредитную, карту, visa, c...   \n",
       "5174  [общем, история, такая, публикую, переписку, д...   \n",
       "6535  [вчера, обратилась, офис, мособлбанка, находящ...   \n",
       "\n",
       "                                              Sequences  \n",
       "idx                                                      \n",
       "7292  [529, 69, 1138, 2, 1622, 616, 6, 1282, 1184, 5...  \n",
       "342   [99, 53, 88, 2, 15, 1536, 97, 2040, 63, 303, 2...  \n",
       "2216  [148, 1080, 8545, 23, 87, 50, 2, 202, 1801, 24...  \n",
       "2606  [555, 2520, 6, 631, 1618, 8, 776, 2, 559, 417,...  \n",
       "6572  [148, 10, 246, 1889, 2, 4, 209, 4565, 1592, 83...  \n",
       "...                                                 ...  \n",
       "7754  [87, 3460, 2063, 499, 2018, 555, 4086, 1189, 3...  \n",
       "7023  [289, 7086, 317, 15, 838, 420, 2327, 2503, 615...  \n",
       "668   [2052, 54, 138, 6, 499, 1952, 882, 7695, 1082,...  \n",
       "5174  [112, 355, 334, 7743, 6466, 531, 9965, 1917, 3...  \n",
       "6535  [394, 340, 33, 4472, 5552, 485, 7411, 1230, 65...  \n",
       "\n",
       "[2800 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделяем метки классов и данные для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = train['Sequences']\n",
    "y_train = train['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "3363     [95, 9206, 148, 10, 5803, 66, 949, 24, 23, 460...\n",
       "4365     [523, 5188, 5, 8, 1489, 2, 649, 1352, 186, 261...\n",
       "259      [1962, 15, 2149, 79, 21, 332, 506, 3343, 23, 1...\n",
       "12038    [163, 1503, 1728, 6, 13, 671, 3406, 586, 3802,...\n",
       "3784     [579, 3782, 2221, 724, 5430, 261, 2567, 1635, ...\n",
       "                               ...                        \n",
       "7797     [35, 965, 207, 815, 1010, 385, 1402, 1487, 428...\n",
       "6937     [231, 780, 2913, 1782, 154, 7161, 5279, 7, 178...\n",
       "5824     [1215, 74, 873, 47, 1609, 394, 621, 1052, 5851...\n",
       "4858     [1514, 259, 726, 283, 158, 683, 12, 47, 1108, ...\n",
       "2394     [503, 157, 6027, 876, 29, 9006, 5581, 1867, 78...\n",
       "Name: Sequences, Length: 11199, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "3363     0\n",
       "4365     0\n",
       "259      1\n",
       "12038    0\n",
       "3784     0\n",
       "        ..\n",
       "7797     1\n",
       "6937     1\n",
       "5824     1\n",
       "4858     0\n",
       "2394     1\n",
       "Name: Score, Length: 11199, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_seq = test['Sequences']\n",
    "y_test = test['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "7292    [529, 69, 1138, 2, 1622, 616, 6, 1282, 1184, 5...\n",
       "342     [99, 53, 88, 2, 15, 1536, 97, 2040, 63, 303, 2...\n",
       "2216    [148, 1080, 8545, 23, 87, 50, 2, 202, 1801, 24...\n",
       "2606    [555, 2520, 6, 631, 1618, 8, 776, 2, 559, 417,...\n",
       "6572    [148, 10, 246, 1889, 2, 4, 209, 4565, 1592, 83...\n",
       "                              ...                        \n",
       "7754    [87, 3460, 2063, 499, 2018, 555, 4086, 1189, 3...\n",
       "7023    [289, 7086, 317, 15, 838, 420, 2327, 2503, 615...\n",
       "668     [2052, 54, 138, 6, 499, 1952, 882, 7695, 1082,...\n",
       "5174    [112, 355, 334, 7743, 6466, 531, 9965, 1917, 3...\n",
       "6535    [394, 340, 33, 4472, 5552, 485, 7411, 1230, 65...\n",
       "Name: Sequences, Length: 2800, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "7292    0\n",
       "342     0\n",
       "2216    0\n",
       "2606    0\n",
       "6572    0\n",
       "       ..\n",
       "7754    1\n",
       "7023    0\n",
       "668     0\n",
       "5174    0\n",
       "6535    1\n",
       "Name: Score, Length: 2800, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for index in sequence:\n",
    "            results[i, index] += 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(x_train_seq, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorize_sequences(x_test_seq, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 2., 0., 2., 0., 0., 2., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 3., 3., 1., 2., 0., 0., 0., 3., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=random_state, max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оцениваем качество обучения на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем долю правильных ответов (accuracy) на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439285714285715"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применяем модель для определения тональности отзыва на банк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Позитивный отзыв**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text = \"\"\"Брал кредит в Мегабанке на автомобиль. Выдали за один день. Никаких скрытых комиссий и переплат.\n",
    "У банка удобное мобильное приложение, через которое можно быстро отправить ежемесячный платеж.\n",
    "Досрочное гасить начал через три месяца. Я доволен оперативностью и удобством. Огромное спасибо!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка текста к обработке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_preprocessed_text = preprocess(positive_text, stops_words_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['брал',\n",
       " 'кредит',\n",
       " 'мегабанке',\n",
       " 'автомобиль',\n",
       " 'выдали',\n",
       " 'день',\n",
       " 'никаких',\n",
       " 'скрытых',\n",
       " 'комиссий',\n",
       " 'переплат',\n",
       " 'банка',\n",
       " 'удобное',\n",
       " 'мобильное',\n",
       " 'приложение',\n",
       " 'которое',\n",
       " 'быстро',\n",
       " 'отправить',\n",
       " 'ежемесячный',\n",
       " 'платеж',\n",
       " 'досрочное',\n",
       " 'гасить',\n",
       " 'начал',\n",
       " 'месяца',\n",
       " 'доволен',\n",
       " 'оперативностью',\n",
       " 'удобством',\n",
       " 'огромное',\n",
       " 'спасибо']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_seq = text_to_sequence(positive_preprocessed_text, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[566,\n",
       " 9,\n",
       " 1678,\n",
       " 440,\n",
       " 10,\n",
       " 81,\n",
       " 3936,\n",
       " 1021,\n",
       " 7789,\n",
       " 2,\n",
       " 1568,\n",
       " 3084,\n",
       " 1338,\n",
       " 598,\n",
       " 56,\n",
       " 874,\n",
       " 1435,\n",
       " 100,\n",
       " 800,\n",
       " 2645,\n",
       " 560,\n",
       " 93,\n",
       " 453,\n",
       " 6657,\n",
       " 548,\n",
       " 25]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bow = vectorize_sequences([positive_seq], max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_bow[0][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем распознавание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lr.predict(positive_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Негативный отзыв**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_text = \"\"\"Взял кредит в ТакСебеБанке на автомобиль. В договор включили обязательный контракт\n",
    "на помощь на дороге, который мне не нужен. Узнал об этом только во время подписания договора, иначе бы отказался.\n",
    "Альтернативы была страхование жизни, но мне это даже не предложили. Скорее всего, менеджер продвигает\n",
    "продажи услуг этой компании в ущерб интересов клиента. Как минимум, непорядочно и непрофессионально.\n",
    "У банка ужасное мобильное приложение, из-за которого с меня взяли штраф 10 тыс.руб. По требованиям\n",
    "банка после покупки автомобиля в приложении нужно загрузить ПТС. Я загрузил и проверил, что ПТС в приложении есть.\n",
    "Но через некоторое время ПТС из приложения пропал и с меня взяли штраф. Никому не рекомендую связываться с ТакСебеБанком.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_preprocessed_text = preprocess(negative_text, stops_words_ru)\n",
    "negative_seq = text_to_sequence(negative_preprocessed_text, word_to_index)\n",
    "negative_bow = vectorize_sequences([negative_seq], max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 2., 0., 1., 0., 0., 0., 0., 1., 0., 2., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_bow[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lr.predict(negative_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lr.predict_proba(negative_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61580654, 0.38419346]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
